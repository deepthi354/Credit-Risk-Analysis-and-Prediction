{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  DATA EXTRACTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset shape :\n",
      "(307511, 122)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>...</th>\n",
       "      <th>FLAG_DOCUMENT_18</th>\n",
       "      <th>FLAG_DOCUMENT_19</th>\n",
       "      <th>FLAG_DOCUMENT_20</th>\n",
       "      <th>FLAG_DOCUMENT_21</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_HOUR</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_DAY</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_WEEK</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_MON</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_QRT</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_YEAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100002</td>\n",
       "      <td>1</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>406597.5</td>\n",
       "      <td>24700.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100003</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>1293502.5</td>\n",
       "      <td>35698.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100004</td>\n",
       "      <td>0</td>\n",
       "      <td>Revolving loans</td>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>67500.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>6750.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100006</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>312682.5</td>\n",
       "      <td>29686.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100007</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>121500.0</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>21865.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 122 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_ID_CURR  TARGET NAME_CONTRACT_TYPE CODE_GENDER FLAG_OWN_CAR  \\\n",
       "0      100002       1         Cash loans           M            N   \n",
       "1      100003       0         Cash loans           F            N   \n",
       "2      100004       0    Revolving loans           M            Y   \n",
       "3      100006       0         Cash loans           F            N   \n",
       "4      100007       0         Cash loans           M            N   \n",
       "\n",
       "  FLAG_OWN_REALTY  CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  \\\n",
       "0               Y             0          202500.0    406597.5      24700.5   \n",
       "1               N             0          270000.0   1293502.5      35698.5   \n",
       "2               Y             0           67500.0    135000.0       6750.0   \n",
       "3               Y             0          135000.0    312682.5      29686.5   \n",
       "4               Y             0          121500.0    513000.0      21865.5   \n",
       "\n",
       "   ...  FLAG_DOCUMENT_18 FLAG_DOCUMENT_19 FLAG_DOCUMENT_20 FLAG_DOCUMENT_21  \\\n",
       "0  ...                 0                0                0                0   \n",
       "1  ...                 0                0                0                0   \n",
       "2  ...                 0                0                0                0   \n",
       "3  ...                 0                0                0                0   \n",
       "4  ...                 0                0                0                0   \n",
       "\n",
       "  AMT_REQ_CREDIT_BUREAU_HOUR AMT_REQ_CREDIT_BUREAU_DAY  \\\n",
       "0                        0.0                       0.0   \n",
       "1                        0.0                       0.0   \n",
       "2                        0.0                       0.0   \n",
       "3                        NaN                       NaN   \n",
       "4                        0.0                       0.0   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_WEEK  AMT_REQ_CREDIT_BUREAU_MON  \\\n",
       "0                         0.0                        0.0   \n",
       "1                         0.0                        0.0   \n",
       "2                         0.0                        0.0   \n",
       "3                         NaN                        NaN   \n",
       "4                         0.0                        0.0   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_QRT  AMT_REQ_CREDIT_BUREAU_YEAR  \n",
       "0                        0.0                         1.0  \n",
       "1                        0.0                         0.0  \n",
       "2                        0.0                         0.0  \n",
       "3                        NaN                         NaN  \n",
       "4                        0.0                         0.0  \n",
       "\n",
       "[5 rows x 122 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STEP1 - DATA EXTRACTION\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "initial_trainset = pd.read_csv(r'D:\\Study Material\\Datascience\\Project- Home Loan Credit Risk Modelling\\Dataset\\application_train.csv')\n",
    "# r (raw data indication) is necessary here otherwise, python will consider backslash as escape character. Eg: \\t implies tab \\n implies new line \n",
    "\n",
    "print (\"Train dataset shape :\")\n",
    "print (initial_trainset.shape)\n",
    "initial_trainset.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset shape :\n",
      "(48744, 121)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <th>...</th>\n",
       "      <th>FLAG_DOCUMENT_18</th>\n",
       "      <th>FLAG_DOCUMENT_19</th>\n",
       "      <th>FLAG_DOCUMENT_20</th>\n",
       "      <th>FLAG_DOCUMENT_21</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_HOUR</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_DAY</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_WEEK</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_MON</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_QRT</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_YEAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>568800.0</td>\n",
       "      <td>20560.5</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100005</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>99000.0</td>\n",
       "      <td>222768.0</td>\n",
       "      <td>17370.0</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100013</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>663264.0</td>\n",
       "      <td>69777.0</td>\n",
       "      <td>630000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100028</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>2</td>\n",
       "      <td>315000.0</td>\n",
       "      <td>1575000.0</td>\n",
       "      <td>49018.5</td>\n",
       "      <td>1575000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100038</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>625500.0</td>\n",
       "      <td>32067.0</td>\n",
       "      <td>625500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_ID_CURR NAME_CONTRACT_TYPE CODE_GENDER FLAG_OWN_CAR FLAG_OWN_REALTY  \\\n",
       "0      100001         Cash loans           F            N               Y   \n",
       "1      100005         Cash loans           M            N               Y   \n",
       "2      100013         Cash loans           M            Y               Y   \n",
       "3      100028         Cash loans           F            N               Y   \n",
       "4      100038         Cash loans           M            Y               N   \n",
       "\n",
       "   CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  AMT_GOODS_PRICE  \\\n",
       "0             0          135000.0    568800.0      20560.5         450000.0   \n",
       "1             0           99000.0    222768.0      17370.0         180000.0   \n",
       "2             0          202500.0    663264.0      69777.0         630000.0   \n",
       "3             2          315000.0   1575000.0      49018.5        1575000.0   \n",
       "4             1          180000.0    625500.0      32067.0         625500.0   \n",
       "\n",
       "   ... FLAG_DOCUMENT_18 FLAG_DOCUMENT_19 FLAG_DOCUMENT_20 FLAG_DOCUMENT_21  \\\n",
       "0  ...                0                0                0                0   \n",
       "1  ...                0                0                0                0   \n",
       "2  ...                0                0                0                0   \n",
       "3  ...                0                0                0                0   \n",
       "4  ...                0                0                0                0   \n",
       "\n",
       "  AMT_REQ_CREDIT_BUREAU_HOUR  AMT_REQ_CREDIT_BUREAU_DAY  \\\n",
       "0                        0.0                        0.0   \n",
       "1                        0.0                        0.0   \n",
       "2                        0.0                        0.0   \n",
       "3                        0.0                        0.0   \n",
       "4                        NaN                        NaN   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_WEEK  AMT_REQ_CREDIT_BUREAU_MON  \\\n",
       "0                         0.0                        0.0   \n",
       "1                         0.0                        0.0   \n",
       "2                         0.0                        0.0   \n",
       "3                         0.0                        0.0   \n",
       "4                         NaN                        NaN   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_QRT  AMT_REQ_CREDIT_BUREAU_YEAR  \n",
       "0                        0.0                         0.0  \n",
       "1                        0.0                         3.0  \n",
       "2                        1.0                         4.0  \n",
       "3                        0.0                         3.0  \n",
       "4                        NaN                         NaN  \n",
       "\n",
       "[5 rows x 121 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_testset = pd.read_csv(r'D:\\Study Material\\Datascience\\Project- Home Loan Credit Risk Modelling\\Dataset\\application_test.csv')\n",
    "\n",
    "print (\"Test dataset shape :\")\n",
    "print (initial_testset.shape)\n",
    "initial_testset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - From above shape details, we can infer that the provided test dataset is 1/6th of the size of the training dataset.\n",
    "\n",
    " - We shall first align both train & test datasets on the basis of common columns so that we do not spend time on pre-processing columns that we later need to remove/drop.\n",
    "\n",
    " - Before we align, extract Target var from train dataset so that it does not get implicitly removed during the process of aligning with test dataset which does not contain target var."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligned Train dataset shape is :  (307511, 122)\n",
      "Aligned Test dataset shape is :  (48744, 121)\n"
     ]
    }
   ],
   "source": [
    "# Aligning train & test set columns\n",
    "\n",
    "target_var=initial_trainset['TARGET']\n",
    "initial_trainset, initial_testset = initial_trainset.align(initial_testset, join=\"inner\", axis=1)\n",
    "initial_trainset['TARGET'] = target_var\n",
    "\n",
    "print('Aligned Train dataset shape is : ', initial_trainset.shape)\n",
    "print('Aligned Test dataset shape is : ', initial_testset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Observe that no column in train or test dataset got removed. It implies that it is the same set of columns that are present in both datasets. Also, with align method, order of columns between the two datasets got synchronized. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  DATA EXPLORATION\n",
    "\n",
    "- Now check for bias in target variable distribution in the train dataset. This is to check if any oversampling or undersampling techniques need to be applied to reduce biased outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias in target column of Trainset :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0.919271\n",
       "1    0.080729\n",
       "Name: TARGET, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print ('Bias in target column of Trainset :')\n",
    "initial_trainset['TARGET'].value_counts(normalize=True)  \n",
    "# 'normalize = True' gives relative frequencies (i.e. %) of each unique value in the column "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  - 92% data is for non-defaulters and 8% for defaulters. It is a highly biased dataset and should ideally be treated. However, for now, let's leave it as-is. We shall revisit this if the model performance is too low.\n",
    "  \n",
    "  - Since this is a prediction problem, testset does not contain target var. Hence checking for bias in testset is not applicable in this case. \n",
    "  \n",
    "  - For further data exploration, we need to check & treat the following-\n",
    "         - Check the various data type of columns present in the data set. \n",
    "         - Impute missing values for both numeric & categorical vars.\n",
    "         - Analyze outliers and drop them to make the model more regularized (even for genuinely valid outlier data)\n",
    "         - Perform one hot encoding of all categorical vars (i.e. create dummy numerical vars)\n",
    "         - Standardize all numerical vars \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  DataType  Count\n",
      "0  float64     65\n",
      "1    int64     41\n",
      "2   object     16\n"
     ]
    }
   ],
   "source": [
    "# For imputation we first need to know the various types of vars present in the dataset.\n",
    "\n",
    "df_datatypes= pd.DataFrame(initial_trainset.dtypes.value_counts()).reset_index()\n",
    "df_datatypes.columns = ['DataType','Count']\n",
    "print(df_datatypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Let us first check what kind of values are present in columns of \"Object\" datatype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>NAME_TYPE_SUITE</th>\n",
       "      <th>NAME_INCOME_TYPE</th>\n",
       "      <th>NAME_EDUCATION_TYPE</th>\n",
       "      <th>NAME_FAMILY_STATUS</th>\n",
       "      <th>NAME_HOUSING_TYPE</th>\n",
       "      <th>OCCUPATION_TYPE</th>\n",
       "      <th>WEEKDAY_APPR_PROCESS_START</th>\n",
       "      <th>ORGANIZATION_TYPE</th>\n",
       "      <th>FONDKAPREMONT_MODE</th>\n",
       "      <th>HOUSETYPE_MODE</th>\n",
       "      <th>WALLSMATERIAL_MODE</th>\n",
       "      <th>EMERGENCYSTATE_MODE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Unaccompanied</td>\n",
       "      <td>Working</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Single / not married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>Laborers</td>\n",
       "      <td>WEDNESDAY</td>\n",
       "      <td>Business Entity Type 3</td>\n",
       "      <td>reg oper account</td>\n",
       "      <td>block of flats</td>\n",
       "      <td>Stone, brick</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Family</td>\n",
       "      <td>State servant</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>Core staff</td>\n",
       "      <td>MONDAY</td>\n",
       "      <td>School</td>\n",
       "      <td>reg oper account</td>\n",
       "      <td>block of flats</td>\n",
       "      <td>Block</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Revolving loans</td>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>Unaccompanied</td>\n",
       "      <td>Working</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Single / not married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>Laborers</td>\n",
       "      <td>MONDAY</td>\n",
       "      <td>Government</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Unaccompanied</td>\n",
       "      <td>Working</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Civil marriage</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>Laborers</td>\n",
       "      <td>WEDNESDAY</td>\n",
       "      <td>Business Entity Type 3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Unaccompanied</td>\n",
       "      <td>Working</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Single / not married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>Core staff</td>\n",
       "      <td>THURSDAY</td>\n",
       "      <td>Religion</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  NAME_CONTRACT_TYPE CODE_GENDER FLAG_OWN_CAR FLAG_OWN_REALTY NAME_TYPE_SUITE  \\\n",
       "0         Cash loans           M            N               Y   Unaccompanied   \n",
       "1         Cash loans           F            N               N          Family   \n",
       "2    Revolving loans           M            Y               Y   Unaccompanied   \n",
       "3         Cash loans           F            N               Y   Unaccompanied   \n",
       "4         Cash loans           M            N               Y   Unaccompanied   \n",
       "\n",
       "  NAME_INCOME_TYPE            NAME_EDUCATION_TYPE    NAME_FAMILY_STATUS  \\\n",
       "0          Working  Secondary / secondary special  Single / not married   \n",
       "1    State servant               Higher education               Married   \n",
       "2          Working  Secondary / secondary special  Single / not married   \n",
       "3          Working  Secondary / secondary special        Civil marriage   \n",
       "4          Working  Secondary / secondary special  Single / not married   \n",
       "\n",
       "   NAME_HOUSING_TYPE OCCUPATION_TYPE WEEKDAY_APPR_PROCESS_START  \\\n",
       "0  House / apartment        Laborers                  WEDNESDAY   \n",
       "1  House / apartment      Core staff                     MONDAY   \n",
       "2  House / apartment        Laborers                     MONDAY   \n",
       "3  House / apartment        Laborers                  WEDNESDAY   \n",
       "4  House / apartment      Core staff                   THURSDAY   \n",
       "\n",
       "        ORGANIZATION_TYPE FONDKAPREMONT_MODE  HOUSETYPE_MODE  \\\n",
       "0  Business Entity Type 3   reg oper account  block of flats   \n",
       "1                  School   reg oper account  block of flats   \n",
       "2              Government                NaN             NaN   \n",
       "3  Business Entity Type 3                NaN             NaN   \n",
       "4                Religion                NaN             NaN   \n",
       "\n",
       "  WALLSMATERIAL_MODE EMERGENCYSTATE_MODE  \n",
       "0       Stone, brick                  No  \n",
       "1              Block                  No  \n",
       "2                NaN                 NaN  \n",
       "3                NaN                 NaN  \n",
       "4                NaN                 NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separating categorical & numerical vars for convenience of imputation\n",
    "\n",
    "cat_trainset = initial_trainset.loc[ : , initial_trainset.dtypes == np.object]\n",
    "cat_testset = initial_testset.loc[ : , initial_testset.dtypes == np.object]\n",
    "cat_trainset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <th>REGION_POPULATION_RELATIVE</th>\n",
       "      <th>DAYS_REGISTRATION</th>\n",
       "      <th>OWN_CAR_AGE</th>\n",
       "      <th>CNT_FAM_MEMBERS</th>\n",
       "      <th>EXT_SOURCE_1</th>\n",
       "      <th>EXT_SOURCE_2</th>\n",
       "      <th>...</th>\n",
       "      <th>FLAG_DOCUMENT_13</th>\n",
       "      <th>FLAG_DOCUMENT_14</th>\n",
       "      <th>FLAG_DOCUMENT_15</th>\n",
       "      <th>FLAG_DOCUMENT_16</th>\n",
       "      <th>FLAG_DOCUMENT_17</th>\n",
       "      <th>FLAG_DOCUMENT_18</th>\n",
       "      <th>FLAG_DOCUMENT_19</th>\n",
       "      <th>FLAG_DOCUMENT_20</th>\n",
       "      <th>FLAG_DOCUMENT_21</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>202500.0</td>\n",
       "      <td>406597.5</td>\n",
       "      <td>24700.5</td>\n",
       "      <td>351000.0</td>\n",
       "      <td>0.018801</td>\n",
       "      <td>-3648.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.083037</td>\n",
       "      <td>0.262949</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>270000.0</td>\n",
       "      <td>1293502.5</td>\n",
       "      <td>35698.5</td>\n",
       "      <td>1129500.0</td>\n",
       "      <td>0.003541</td>\n",
       "      <td>-1186.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.311267</td>\n",
       "      <td>0.622246</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67500.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>6750.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>0.010032</td>\n",
       "      <td>-4260.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.555912</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>135000.0</td>\n",
       "      <td>312682.5</td>\n",
       "      <td>29686.5</td>\n",
       "      <td>297000.0</td>\n",
       "      <td>0.008019</td>\n",
       "      <td>-9833.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650442</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>121500.0</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>21865.5</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>0.028663</td>\n",
       "      <td>-4311.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.322738</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  AMT_GOODS_PRICE  \\\n",
       "0          202500.0    406597.5      24700.5         351000.0   \n",
       "1          270000.0   1293502.5      35698.5        1129500.0   \n",
       "2           67500.0    135000.0       6750.0         135000.0   \n",
       "3          135000.0    312682.5      29686.5         297000.0   \n",
       "4          121500.0    513000.0      21865.5         513000.0   \n",
       "\n",
       "   REGION_POPULATION_RELATIVE  DAYS_REGISTRATION  OWN_CAR_AGE  \\\n",
       "0                    0.018801            -3648.0          NaN   \n",
       "1                    0.003541            -1186.0          NaN   \n",
       "2                    0.010032            -4260.0         26.0   \n",
       "3                    0.008019            -9833.0          NaN   \n",
       "4                    0.028663            -4311.0          NaN   \n",
       "\n",
       "   CNT_FAM_MEMBERS  EXT_SOURCE_1  EXT_SOURCE_2  ...  FLAG_DOCUMENT_13  \\\n",
       "0              1.0      0.083037      0.262949  ...                 0   \n",
       "1              2.0      0.311267      0.622246  ...                 0   \n",
       "2              1.0           NaN      0.555912  ...                 0   \n",
       "3              2.0           NaN      0.650442  ...                 0   \n",
       "4              1.0           NaN      0.322738  ...                 0   \n",
       "\n",
       "   FLAG_DOCUMENT_14  FLAG_DOCUMENT_15  FLAG_DOCUMENT_16  FLAG_DOCUMENT_17  \\\n",
       "0                 0                 0                 0                 0   \n",
       "1                 0                 0                 0                 0   \n",
       "2                 0                 0                 0                 0   \n",
       "3                 0                 0                 0                 0   \n",
       "4                 0                 0                 0                 0   \n",
       "\n",
       "   FLAG_DOCUMENT_18  FLAG_DOCUMENT_19  FLAG_DOCUMENT_20  FLAG_DOCUMENT_21  \\\n",
       "0                 0                 0                 0                 0   \n",
       "1                 0                 0                 0                 0   \n",
       "2                 0                 0                 0                 0   \n",
       "3                 0                 0                 0                 0   \n",
       "4                 0                 0                 0                 0   \n",
       "\n",
       "   TARGET  \n",
       "0       1  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  \n",
       "\n",
       "[5 rows x 106 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separating numerical vars\n",
    "\n",
    "float_trainset = initial_trainset.loc[ : , initial_trainset.dtypes == np.float64 ]\n",
    "int_trainset = initial_trainset.loc[ : , initial_trainset.dtypes == np.int64]\n",
    "num_trainset = pd.concat([float_trainset, int_trainset], axis = 1)\n",
    "\n",
    "\n",
    "float_testset = initial_testset.loc[ : , initial_testset.dtypes == np.float64 ]\n",
    "int_testset = initial_testset.loc[ : , initial_testset.dtypes == np.int64]\n",
    "num_testset = pd.concat([float_testset, int_testset], axis = 1)\n",
    "\n",
    "num_trainset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treating Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values in categorical columns of train set:\n",
      "           Column_name  Percent_missing\n",
      "12  FONDKAPREMONT_MODE        68.386172\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "Number of missing values in categorical columns of TEST set:\n",
      "           Column_name  Percent_missing\n",
      "12  FONDKAPREMONT_MODE        68.386172\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "Number of missing values in numeric columns of train set :\n",
      "                 Column_name  Percent_missing\n",
      "6                OWN_CAR_AGE        65.990810\n",
      "14           YEARS_BUILD_AVG        66.497784\n",
      "15            COMMONAREA_AVG        69.872297\n",
      "19             FLOORSMIN_AVG        67.848630\n",
      "21      LIVINGAPARTMENTS_AVG        68.354953\n",
      "23   NONLIVINGAPARTMENTS_AVG        69.432963\n",
      "28          YEARS_BUILD_MODE        66.497784\n",
      "29           COMMONAREA_MODE        69.872297\n",
      "33            FLOORSMIN_MODE        67.848630\n",
      "35     LIVINGAPARTMENTS_MODE        68.354953\n",
      "37  NONLIVINGAPARTMENTS_MODE        69.432963\n",
      "42          YEARS_BUILD_MEDI        66.497784\n",
      "43           COMMONAREA_MEDI        69.872297\n",
      "47            FLOORSMIN_MEDI        67.848630\n",
      "49     LIVINGAPARTMENTS_MEDI        68.354953\n",
      "51  NONLIVINGAPARTMENTS_MEDI        69.432963\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "Number of missing values in numeric columns of TEST set :\n",
      "                 Column_name  Percent_missing\n",
      "6                OWN_CAR_AGE        66.289184\n",
      "14           YEARS_BUILD_AVG        65.275726\n",
      "15            COMMONAREA_AVG        68.716150\n",
      "19             FLOORSMIN_AVG        66.605121\n",
      "21      LIVINGAPARTMENTS_AVG        67.249302\n",
      "23   NONLIVINGAPARTMENTS_AVG        68.412523\n",
      "28          YEARS_BUILD_MODE        65.275726\n",
      "29           COMMONAREA_MODE        68.716150\n",
      "33            FLOORSMIN_MODE        66.605121\n",
      "35     LIVINGAPARTMENTS_MODE        67.249302\n",
      "37  NONLIVINGAPARTMENTS_MODE        68.412523\n",
      "42          YEARS_BUILD_MEDI        65.275726\n",
      "43           COMMONAREA_MEDI        68.716150\n",
      "47            FLOORSMIN_MEDI        66.605121\n",
      "49     LIVINGAPARTMENTS_MEDI        67.249302\n",
      "51  NONLIVINGAPARTMENTS_MEDI        68.412523\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n"
     ]
    }
   ],
   "source": [
    "# check missing values in both categorical & numeric vars.\n",
    "# single - sum() will return sum of null values per each column\n",
    "# double - sum().sum() will return total null values across all cols of dataframe\n",
    "\n",
    "print (\"Number of missing values in categorical columns of train set:\")\n",
    "missing = pd.DataFrame((cat_trainset.isnull().sum()/cat_trainset.shape[0])*100).reset_index()\n",
    "missing.columns = ['Column_name', 'Percent_missing']\n",
    "Train_cat_missing = missing.loc[missing['Percent_missing']>60]\n",
    "print (Train_cat_missing)\n",
    "print ('_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _')\n",
    "\n",
    "print (\"Number of missing values in categorical columns of TEST set:\")\n",
    "missing = pd.DataFrame((cat_testset.isnull().sum()/cat_testset.shape[0])*100).reset_index()\n",
    "missing.columns = ['Column_name', 'Percent_missing']\n",
    "Test_cat_missing = missing.loc[missing['Percent_missing']>60]\n",
    "print (Train_cat_missing)\n",
    "print ('_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _')\n",
    "\n",
    "print (\"Number of missing values in numeric columns of train set :\")\n",
    "missing = pd.DataFrame((num_trainset.isnull().sum()/num_trainset.shape[0])*100).reset_index()\n",
    "missing.columns = ['Column_name', 'Percent_missing']\n",
    "Train_num_missing = missing.loc[missing['Percent_missing']>60]\n",
    "print (Train_num_missing)\n",
    "print ('_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _')\n",
    "\n",
    "print (\"Number of missing values in numeric columns of TEST set :\")\n",
    "missing = pd.DataFrame((num_testset.isnull().sum()/num_testset.shape[0])*100).reset_index()\n",
    "missing.columns = ['Column_name', 'Percent_missing']\n",
    "Test_num_missing = missing.loc[missing['Percent_missing']>60]\n",
    "print (Test_num_missing)\n",
    "print ('_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  - It is ideal to remove columns that have more than 60% of missing values in both train & test datasets, because even if we impute those missing values, data is not real time data. Therefore model performance wont fit real time unseen data well. \n",
    "  - From above result we can remove \"FONDKAPREMONT_MODE\" column from categorical train & test sets\n",
    "  - For numeric missing values, we can remove the 16 columns listed in above result set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For CATEGORICAL TRAINSET-\n",
      "shape BEFORE drop is : (307511, 16)\n",
      "shape AFTER drop is : (307511, 15)\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "For CATEGORICAL TESTSET-\n",
      "shape BEFORE drop is : (48744, 16)\n",
      "shape AFTER drop is : (48744, 15)\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "For NUMERICAL TRAINSET-\n",
      "shape BEFORE drop is : (307511, 106)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3940: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape AFTER drop is : (307511, 90)\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "For NUMERICAL TESTSET-\n",
      "numerical trainset: (48744, 105) \n",
      "numerical testset: (48744, 89) \n"
     ]
    }
   ],
   "source": [
    "# removing columns that have more than 60% missing values in both train & test data sets\n",
    "\n",
    "print('For CATEGORICAL TRAINSET-')\n",
    "print('shape BEFORE drop is : {}'.format(cat_trainset.shape))\n",
    "cat_trainset.drop(Train_cat_missing['Column_name'], axis=1, inplace=True)\n",
    "print('shape AFTER drop is : {}'.format(cat_trainset.shape))\n",
    "print ('_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _')\n",
    "\n",
    "print('For CATEGORICAL TESTSET-')\n",
    "print('shape BEFORE drop is : {}'.format(cat_testset.shape))\n",
    "cat_testset.drop(Test_cat_missing['Column_name'], axis = 1, inplace=True)\n",
    "print('shape AFTER drop is : {}'.format(cat_testset.shape))\n",
    "print ('_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _')\n",
    "\n",
    "print('For NUMERICAL TRAINSET-')\n",
    "print('shape BEFORE drop is : {}'.format(num_trainset.shape))\n",
    "num_trainset.drop(Train_num_missing['Column_name'], axis = 1, inplace=True)\n",
    "print('shape AFTER drop is : {}'.format(num_trainset.shape))\n",
    "print ('_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _')\n",
    "\n",
    "print('For NUMERICAL TESTSET-')\n",
    "print('numerical trainset: {} '.format (num_testset.shape))\n",
    "num_testset.drop(Test_num_missing['Column_name'], axis = 1, inplace=True)\n",
    "print('numerical testset: {} '.format (num_testset.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  - Notice that num test set has one column less than its num train set. This is because of the absence of 'TARGET' var in the test set. We shall deal with this in a while. \n",
    "  - Therefore, before using Impute library to transform all missing values in test set using impute parameters calculated on the basis of trainset, we should make sure the columns in train & test set match. Otherwise it will throw error. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back to Missing Value Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307511, 89)\n",
      "(48744, 89)\n"
     ]
    }
   ],
   "source": [
    "# The only non-common column between train & test sets is 'TARGET'. Extract and handle this column separately for sometime. \n",
    "# During use of align() method, we already stored target data in 'target_var'. We shall re-use this now.\n",
    "\n",
    "num_trainset.drop(['TARGET'], axis =1, inplace=True)\n",
    "print(num_trainset.shape)\n",
    "print(num_testset.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if target var has any missing values. If yes, remove those rows.\n",
    "\n",
    "target_var.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  -  There are no missing values in target variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Storing column names  [this is only for back up purpose]\n",
    "\n",
    "Cols_in_cat_train = cat_trainset.columns\n",
    "Cols_in_cat_test = cat_testset.columns\n",
    "Cols_in_num_train = num_trainset.columns\n",
    "Cols_in_num_test = columns= num_testset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to impute missing values using SimpleImputer method is 64.75418051083882\n"
     ]
    }
   ],
   "source": [
    "# Imputing missing values in cat & num vars\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "impute = SimpleImputer(missing_values = np.NaN, strategy = 'most_frequent')\n",
    "imputed_cat_trainset = pd.DataFrame(impute.fit_transform(cat_trainset),columns=cat_trainset.columns).astype(cat_trainset.dtypes.to_dict()) # this is to impute cat vars with most frequently occurring value in that column.\n",
    "imputed_cat_testset = pd.DataFrame(impute.transform(cat_testset), columns = cat_testset.columns).astype(cat_testset.dtypes.to_dict())\n",
    "\n",
    "impute = SimpleImputer(missing_values = np.NaN, strategy = 'mean')\n",
    "imputed_num_trainset = pd.DataFrame(impute.fit_transform(num_trainset), columns = num_trainset.columns).astype(num_trainset.dtypes.to_dict()) # this is to impute num vars with mean of the column.\n",
    "imputed_num_testset = pd.DataFrame(impute.transform(num_testset), columns= num_testset.columns).astype(num_trainset.dtypes.to_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset:\n",
      "Number of missing values in categorical columns AFTER IMPUTATION:\n",
      "0\n",
      "Number of missing values in numeric columns AFTER IMPUTATION:\n",
      "0\n",
      "Testset:\n",
      "Number of missing values in categorical columns AFTER IMPUTATION:\n",
      "0\n",
      "Number of missing values in numeric columns AFTER IMPUTATION:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# checking if imputation of all missing values is successful or not. \n",
    "\n",
    "print('trainset:')\n",
    "print (\"Number of missing values in categorical columns AFTER IMPUTATION:\")\n",
    "print (imputed_cat_trainset.isnull().sum().sum()) \n",
    "print ('Number of missing values in numeric columns AFTER IMPUTATION:')\n",
    "print (imputed_num_trainset.isnull().sum().sum())\n",
    "\n",
    "print('Testset:')\n",
    "print (\"Number of missing values in categorical columns AFTER IMPUTATION:\")\n",
    "print (imputed_cat_testset.isnull().sum().sum()) \n",
    "print ('Number of missing values in numeric columns AFTER IMPUTATION:')\n",
    "print (imputed_num_testset.isnull().sum().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  - This shows that imputation of missing values across all cat & num vars was successful on both train & test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since use of SimpleImputer is taking too long to run, saving imputed datasets to local drive. \n",
    "# will import these to save time for future runs.\n",
    "\n",
    "#exporting imputed datasets\n",
    "imputed_cat_trainset.to_csv(r'D:\\Study Material\\Datascience\\Project- Home Loan Credit Risk Modelling\\Dataset\\imputed_cat_trainset.csv')\n",
    "imputed_cat_testset.to_csv(r'D:\\Study Material\\Datascience\\Project- Home Loan Credit Risk Modelling\\Dataset\\imputed_cat_testset.csv')\n",
    "imputed_num_trainset.to_csv(r'D:\\Study Material\\Datascience\\Project- Home Loan Credit Risk Modelling\\Dataset\\imputed_num_trainset.csv')\n",
    "imputed_num_testset.to_csv(r'D:\\Study Material\\Datascience\\Project- Home Loan Credit Risk Modelling\\Dataset\\imputed_num_testset.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imputed_cat_trainset shape : (307511, 15)\n",
      "imputed_cat_testset shape : (48744, 15)\n",
      "imputed_num_trainset shape : (307511, 89)\n",
      "imputed_num_testset shape : (48744, 89)\n",
      "0    1\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "Name: TARGET, dtype: int64\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "# USE THIS CODE TO AVOID RUNNING ALL ABOVE CELLS OF CODE \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "initial_trainset = pd.read_csv(r'D:\\Study Material\\Datascience\\Project- Home Loan Credit Risk Modelling\\Dataset\\application_train.csv')\n",
    "imputed_cat_trainset = pd.read_csv(r'D:\\Study Material\\Datascience\\Project- Home Loan Credit Risk Modelling\\Dataset\\imputed_cat_trainset.csv')\n",
    "imputed_cat_testset = pd.read_csv(r'D:\\Study Material\\Datascience\\Project- Home Loan Credit Risk Modelling\\Dataset\\imputed_cat_testset.csv')\n",
    "imputed_num_trainset = pd.read_csv(r'D:\\Study Material\\Datascience\\Project- Home Loan Credit Risk Modelling\\Dataset\\imputed_num_trainset.csv')\n",
    "imputed_num_testset = pd.read_csv(r'D:\\Study Material\\Datascience\\Project- Home Loan Credit Risk Modelling\\Dataset\\imputed_num_testset.csv')\n",
    "\n",
    "# drop 1st column for imputed test sets as index column got added while exporting those files. Hence while importing we must remove it.\n",
    "imputed_cat_trainset.drop(imputed_cat_trainset.columns[0], axis = 1, inplace = True)\n",
    "imputed_cat_testset.drop(imputed_cat_testset.columns[0], axis = 1, inplace = True)\n",
    "imputed_num_trainset.drop(imputed_num_trainset.columns[0], axis = 1, inplace = True)\n",
    "imputed_num_testset.drop(imputed_num_testset.columns[0], axis = 1, inplace = True)\n",
    "\n",
    "print (\"imputed_cat_trainset shape : {}\".format(imputed_cat_trainset.shape))\n",
    "print (\"imputed_cat_testset shape : {}\".format(imputed_cat_testset.shape))\n",
    "print (\"imputed_num_trainset shape : {}\".format(imputed_num_trainset.shape))\n",
    "print (\"imputed_num_testset shape : {}\".format(imputed_num_testset.shape))\n",
    "\n",
    "target_var=initial_trainset['TARGET']\n",
    "print(target_var.head())\n",
    "\n",
    "#checking if any missing values got introduced while exporting/importing\n",
    "print (imputed_cat_trainset.isnull().sum().sum()) \n",
    "print (imputed_cat_testset.isnull().sum().sum()) \n",
    "print (imputed_num_trainset.isnull().sum().sum()) \n",
    "print (imputed_num_testset.isnull().sum().sum()) \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ### Outlier Identification\n",
    "   \n",
    "  -  We could visualize data (using box plots) or summary statistics to calculate how far the min & max data is from its mean & neighbouring data. Any extreme data can be removed or imputed even if it is genuinely valid in real world. This will help regularize our model and reduces a skewed or biased outcome. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    FLAG_EMAIL\n",
      "50           0\n",
      "51           0\n",
      "52           0\n",
      "53           0\n",
      "54           0\n",
      "55           1\n",
      "56           0\n",
      "57           0\n",
      "58           0\n",
      "59           0\n",
      "60           0\n",
      "61           1\n",
      "count    307511.000000\n",
      "mean          0.056720\n",
      "std           0.231307\n",
      "min           0.000000\n",
      "25%           0.000000\n",
      "50%           0.000000\n",
      "75%           0.000000\n",
      "max           1.000000\n",
      "Name: FLAG_EMAIL, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x25101f78860>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for each of the above identified cols, let us visualize summary statistics & visualize data using plots\n",
    "\n",
    "from pprint import pprint \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "%matplotlib inline\n",
    "\n",
    "pprint(imputed_num_trainset.loc[ 50:61, ['FLAG_EMAIL']]) # randomly picking data values in rows 50 to 60 to see what kind of data exist\n",
    "pprint(imputed_num_trainset['FLAG_EMAIL'].describe())\n",
    "\n",
    "plt.title('FLAG_EMAIL')\n",
    "sns.set(style=\"whitegrid\")\n",
    "sns.boxplot( y=imputed_num_trainset['FLAG_EMAIL'] )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - From above results we infer - \n",
    "      1. Data in FLAG_EMAIL column contains only 0s and 1s. So question of outlier does not apply in this case. \n",
    "      2. For this kind of data, we cannot plot the distribution as well. Hence the plots above are uninterpretable. \n",
    " - Therefore, we must ignore all categorical vars and numerical vars with classes, and only look for outliers on continuous numeric values. \n",
    " - For this purpose, let us take sort all columns in ascending order and look at the top 10 & bottom 10 values. If there is huge difference in the spread of values then those can be termed as outliers.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column = AMT_INCOME_TOTAL, Mean = 168797.9192969845, Min = 25650.0, Max = 117000000.0\n",
      "    index  AMT_INCOME_TOTAL\n",
      "0    1678           25650.0\n",
      "1   20727           25650.0\n",
      "2  240137           26100.0\n",
      "3  186643           26100.0\n",
      "4  246104           26100.0\n",
      "5  132707           26460.0\n",
      "    index  AMT_INCOME_TOTAL\n",
      "0  204564         4500000.0\n",
      "1  131127         6750000.0\n",
      "2   77768         9000000.0\n",
      "3  246858        13500000.0\n",
      "4  203693        18000090.0\n",
      "5   12840       117000000.0\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "Column = AMT_CREDIT, Mean = 599025.9997057016, Min = 45000.0, Max = 4050000.0\n",
      "    index  AMT_CREDIT\n",
      "0   51295     45000.0\n",
      "1   43617     45000.0\n",
      "2   72466     45000.0\n",
      "3   91081     45000.0\n",
      "4  136953     45000.0\n",
      "5   64895     45000.0\n",
      "    index  AMT_CREDIT\n",
      "0   14852   4050000.0\n",
      "1   17948   4050000.0\n",
      "2  110459   4050000.0\n",
      "3  133766   4050000.0\n",
      "4  120757   4050000.0\n",
      "5  119681   4050000.0\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "Column = AMT_ANNUITY, Mean = 27108.573909183444, Min = 1615.5, Max = 258025.5\n",
      "    index  AMT_ANNUITY\n",
      "0  277186       1615.5\n",
      "1   73549       1980.0\n",
      "2  145396       1980.0\n",
      "3  125236       1993.5\n",
      "4   17048       2052.0\n",
      "5  227195       2164.5\n",
      "    index  AMT_ANNUITY\n",
      "0  141371     225000.0\n",
      "1   66528     225000.0\n",
      "2  265026     225000.0\n",
      "3   12108     225000.0\n",
      "4  101508     230161.5\n",
      "5   17948     258025.5\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "Column = AMT_GOODS_PRICE, Mean = 538396.2074288887, Min = 40500.0, Max = 4050000.0\n",
      "    index  AMT_GOODS_PRICE\n",
      "0  298542          40500.0\n",
      "1  261862          45000.0\n",
      "2  104277          45000.0\n",
      "3  108374          45000.0\n",
      "4  158668          45000.0\n",
      "5   81179          45000.0\n",
      "    index  AMT_GOODS_PRICE\n",
      "0  119681        4050000.0\n",
      "1  120757        4050000.0\n",
      "2   14852        4050000.0\n",
      "3  288455        4050000.0\n",
      "4   17948        4050000.0\n",
      "5  110459        4050000.0\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "Column = REGION_POPULATION_RELATIVE, Mean = 0.02086811205778947, Min = 0.00029, Max = 0.072508\n",
      "    index  REGION_POPULATION_RELATIVE\n",
      "0  248609                    0.000290\n",
      "1  280258                    0.000290\n",
      "2   79304                    0.000533\n",
      "3   96885                    0.000533\n",
      "4   48168                    0.000533\n",
      "5   96088                    0.000533\n",
      "    index  REGION_POPULATION_RELATIVE\n",
      "0   71412                    0.072508\n",
      "1    8155                    0.072508\n",
      "2  294876                    0.072508\n",
      "3  248718                    0.072508\n",
      "4  288172                    0.072508\n",
      "5   75915                    0.072508\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "Column = DAYS_REGISTRATION, Mean = -4986.120327538419, Min = -24672.0, Max = 0.0\n",
      "    index  DAYS_REGISTRATION\n",
      "0  234093           -24672.0\n",
      "1  163628           -23738.0\n",
      "2  249436           -23416.0\n",
      "3  289176           -22928.0\n",
      "4  210943           -22858.0\n",
      "5  151533           -22701.0\n",
      "    index  DAYS_REGISTRATION\n",
      "0  216434                0.0\n",
      "1  159049                0.0\n",
      "2  116425                0.0\n",
      "3  129287                0.0\n",
      "4   88206                0.0\n",
      "5  126176                0.0\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "Column = CNT_FAM_MEMBERS, Mean = 2.1526654504421012, Min = 1.0, Max = 20.0\n",
      "    index  CNT_FAM_MEMBERS\n",
      "0       0              1.0\n",
      "1  221593              1.0\n",
      "2  221600              1.0\n",
      "3  221608              1.0\n",
      "4   80933              1.0\n",
      "5  221612              1.0\n",
      "    index  CNT_FAM_MEMBERS\n",
      "0   80948             14.0\n",
      "1  176011             15.0\n",
      "2  183878             16.0\n",
      "3  267998             16.0\n",
      "4  155369             20.0\n",
      "5  265784             20.0\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "Column = EXT_SOURCE_1, Mean = 0.502129805655716, Min = 0.014568132412445587, Max = 0.9626927705613059\n",
      "    index  EXT_SOURCE_1\n",
      "0   31640      0.014568\n",
      "1  301455      0.014691\n",
      "2  288960      0.015053\n",
      "3  100928      0.015600\n",
      "4  292280      0.017095\n",
      "5   89158      0.017177\n",
      "    index  EXT_SOURCE_1\n",
      "0  141472      0.945741\n",
      "1  294215      0.946076\n",
      "2  126443      0.946098\n",
      "3  297396      0.947649\n",
      "4   66514      0.951624\n",
      "5  218459      0.962693\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "Column = EXT_SOURCE_2, Mean = 0.5143926741308488, Min = 8.173616518884397e-08, Max = 0.8549996664047012\n",
      "    index  EXT_SOURCE_2\n",
      "0   24022  8.173617e-08\n",
      "1  163598  1.315956e-06\n",
      "2  186074  5.002109e-06\n",
      "3  177315  5.600338e-06\n",
      "4  230344  5.939651e-06\n",
      "5  205088  9.936476e-06\n",
      "    index  EXT_SOURCE_2\n",
      "0  106620         0.855\n",
      "1  150617         0.855\n",
      "2  186222         0.855\n",
      "3  183939         0.855\n",
      "4  294089         0.855\n",
      "5  113237         0.855\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "Column = EXT_SOURCE_3, Mean = 0.5108529061805425, Min = 0.0005272652387098817, Max = 0.8960095494948396\n",
      "    index  EXT_SOURCE_3\n",
      "0   78124      0.000527\n",
      "1  280925      0.000527\n",
      "2  131621      0.000527\n",
      "3    3172      0.000527\n",
      "4  141728      0.000527\n",
      "5  281145      0.000527\n",
      "    index  EXT_SOURCE_3\n",
      "0  218336      0.885488\n",
      "1  142137      0.885488\n",
      "2   91010      0.887664\n",
      "3  180278      0.893976\n",
      "4  189133      0.893976\n",
      "5   29174      0.896010\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "Column = APARTMENTS_AVG, Mean = 0.11744049917501084, Min = 0.0, Max = 1.0\n",
      "    index  APARTMENTS_AVG\n",
      "0   35395             0.0\n",
      "1   64181             0.0\n",
      "2   70590             0.0\n",
      "3   22414             0.0\n",
      "4  249250             0.0\n",
      "5  273518             0.0\n",
      "    index  APARTMENTS_AVG\n",
      "0   51625             1.0\n",
      "1  153256             1.0\n",
      "2   86377             1.0\n",
      "3  257077             1.0\n",
      "4  263961             1.0\n",
      "5  232330             1.0\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "Column = BASEMENTAREA_AVG, Mean = 0.08844221905149156, Min = 0.0, Max = 1.0\n",
      "    index  BASEMENTAREA_AVG\n",
      "0  167229               0.0\n",
      "1   96906               0.0\n",
      "2  196714               0.0\n",
      "3   96917               0.0\n",
      "4  196709               0.0\n",
      "5   10802               0.0\n",
      "    index  BASEMENTAREA_AVG\n",
      "0   10393               1.0\n",
      "1  256617               1.0\n",
      "2  189553               1.0\n",
      "3  112912               1.0\n",
      "4   86134               1.0\n",
      "5   85095               1.0\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "Column = YEARS_BEGINEXPLUATATION_AVG, Mean = 0.9777348581638169, Min = 0.0, Max = 1.0\n",
      "    index  YEARS_BEGINEXPLUATATION_AVG\n",
      "0    4375                          0.0\n",
      "1   19842                          0.0\n",
      "2   29725                          0.0\n",
      "3  306337                          0.0\n",
      "4   47447                          0.0\n",
      "5   90431                          0.0\n",
      "    index  YEARS_BEGINEXPLUATATION_AVG\n",
      "0  303272                          1.0\n",
      "1  225501                          1.0\n",
      "2  200662                          1.0\n",
      "3   42785                          1.0\n",
      "4  291430                          1.0\n",
      "5  237154                          1.0\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "Column = ELEVATORS_AVG, Mean = 0.07894151232434034, Min = 0.0, Max = 1.0\n",
      "    index  ELEVATORS_AVG\n",
      "0       0            0.0\n",
      "1  146556            0.0\n",
      "2  146555            0.0\n",
      "3  146552            0.0\n",
      "4  146548            0.0\n",
      "5  146543            0.0\n",
      "    index  ELEVATORS_AVG\n",
      "0  277020            1.0\n",
      "1   31055            1.0\n",
      "2  281515            1.0\n",
      "3  222945            1.0\n",
      "4   27263            1.0\n",
      "5  139292            1.0\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "Column = ENTRANCES_AVG, Mean = 0.14972467006795898, Min = 0.0, Max = 1.0\n",
      "    index  ENTRANCES_AVG\n",
      "0  293457            0.0\n",
      "1     404            0.0\n",
      "2    2150            0.0\n",
      "3  253125            0.0\n",
      "4   26467            0.0\n",
      "5  215791            0.0\n",
      "    index  ENTRANCES_AVG\n",
      "0  273883            1.0\n",
      "1   11156            1.0\n",
      "2  114652            1.0\n",
      "3  177940            1.0\n",
      "4  128741            1.0\n",
      "5  121466            1.0\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "Column = FLOORSMAX_AVG, Mean = 0.22628190703721907, Min = 0.0, Max = 1.0\n",
      "    index  FLOORSMAX_AVG\n",
      "0  151905            0.0\n",
      "1  266109            0.0\n",
      "2  120714            0.0\n",
      "3  264355            0.0\n",
      "4  292974            0.0\n",
      "5   70567            0.0\n",
      "    index  FLOORSMAX_AVG\n",
      "0  256301            1.0\n",
      "1   61622            1.0\n",
      "2  223241            1.0\n",
      "3    2181            1.0\n",
      "4  128319            1.0\n",
      "5   27902            1.0\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "Column = LANDAREA_AVG, Mean = 0.06633318417209516, Min = 0.0, Max = 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    index  LANDAREA_AVG\n",
      "0  238596           0.0\n",
      "1  250384           0.0\n",
      "2   59660           0.0\n",
      "3  232361           0.0\n",
      "4   11244           0.0\n",
      "5  220854           0.0\n",
      "    index  LANDAREA_AVG\n",
      "0   63931           1.0\n",
      "1  136159           1.0\n",
      "2   17729           1.0\n",
      "3  122526           1.0\n",
      "4  229043           1.0\n",
      "5  106802           1.0\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "Column = LIVINGAREA_AVG, Mean = 0.1073990193326269, Min = 0.0, Max = 1.0\n",
      "    index  LIVINGAREA_AVG\n",
      "0  168681             0.0\n",
      "1    4004             0.0\n",
      "2  280826             0.0\n",
      "3  295839             0.0\n",
      "4  246765             0.0\n",
      "5  287906             0.0\n",
      "    index  LIVINGAREA_AVG\n",
      "0  120887             1.0\n",
      "1  112279             1.0\n",
      "2  287031             1.0\n",
      "3  141185             1.0\n",
      "4   79043             1.0\n",
      "5   67714             1.0\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "Column = NONLIVINGAREA_AVG, Mean = 0.028357757075671827, Min = 0.0, Max = 1.0\n",
      "    index  NONLIVINGAREA_AVG\n",
      "0       0                0.0\n",
      "1  135163                0.0\n",
      "2  135160                0.0\n",
      "3  135158                0.0\n",
      "4  135156                0.0\n",
      "5  135155                0.0\n",
      "    index  NONLIVINGAREA_AVG\n",
      "0  288773                1.0\n",
      "1  162754                1.0\n",
      "2   56833                1.0\n",
      "3    9975                1.0\n",
      "4  152287                1.0\n",
      "5  115754                1.0\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "Column = APARTMENTS_MODE, Mean = 0.1142310069331419, Min = 0.0, Max = 1.0\n",
      "    index  APARTMENTS_MODE\n",
      "0  224787              0.0\n",
      "1   78049              0.0\n",
      "2  301155              0.0\n",
      "3  301167              0.0\n",
      "4  301180              0.0\n",
      "5  285503              0.0\n",
      "    index  APARTMENTS_MODE\n",
      "0  205992              1.0\n",
      "1   78189              1.0\n",
      "2   91963              1.0\n",
      "3  184343              1.0\n",
      "4  304477              1.0\n",
      "5  108567              1.0\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "Column = BASEMENTAREA_MODE, Mean = 0.08754321224791545, Min = 0.0, Max = 1.0\n",
      "    index  BASEMENTAREA_MODE\n",
      "0  222989                0.0\n",
      "1   22792                0.0\n",
      "2  197104                0.0\n",
      "3   98524                0.0\n",
      "4  197095                0.0\n",
      "5  197090                0.0\n",
      "    index  BASEMENTAREA_MODE\n",
      "0  137487                1.0\n",
      "1  280079                1.0\n",
      "2   47897                1.0\n",
      "3  125917                1.0\n",
      "4  276081                1.0\n",
      "5   66470                1.0\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "Column = YEARS_BEGINEXPLUATATION_MODE, Mean = 0.9770653729438351, Min = 0.0, Max = 1.0\n",
      "    index  YEARS_BEGINEXPLUATATION_MODE\n",
      "0  143279                           0.0\n",
      "1  213977                           0.0\n",
      "2   96614                           0.0\n",
      "3   74615                           0.0\n",
      "4  107065                           0.0\n",
      "5   46740                           0.0\n",
      "    index  YEARS_BEGINEXPLUATATION_MODE\n",
      "0  166099                           1.0\n",
      "1  197070                           1.0\n",
      "2   46373                           1.0\n",
      "3   79071                           1.0\n",
      "4  270453                           1.0\n",
      "5  145713                           1.0\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "Column = ELEVATORS_MODE, Mean = 0.07448973610945996, Min = 0.0, Max = 1.0\n",
      "    index  ELEVATORS_MODE\n",
      "0       0             0.0\n",
      "1  148205             0.0\n",
      "2  148203             0.0\n",
      "3  148202             0.0\n",
      "4  148201             0.0\n",
      "5  148199             0.0\n",
      "    index  ELEVATORS_MODE\n",
      "0  277020             1.0\n",
      "1  244802             1.0\n",
      "2  251270             1.0\n",
      "3  153880             1.0\n",
      "4   86377             1.0\n",
      "5  202961             1.0\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "Column = ENTRANCES_MODE, Mean = 0.14519265864566244, Min = 0.0, Max = 1.0\n",
      "    index  ENTRANCES_MODE\n",
      "0  285777             0.0\n",
      "1  198890             0.0\n",
      "2  269159             0.0\n",
      "3   89960             0.0\n",
      "4   66393             0.0\n",
      "5   13583             0.0\n",
      "    index  ENTRANCES_MODE\n",
      "0  115283             1.0\n",
      "1    4838             1.0\n",
      "2   36386             1.0\n",
      "3  293650             1.0\n",
      "4  228407             1.0\n",
      "5  278081             1.0\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "Column = FLOORSMAX_MODE, Mean = 0.22231504747935227, Min = 0.0, Max = 1.0\n",
      "    index  FLOORSMAX_MODE\n",
      "0  273082             0.0\n",
      "1   76716             0.0\n",
      "2  123295             0.0\n",
      "3   93573             0.0\n",
      "4  299856             0.0\n",
      "5  226584             0.0\n",
      "    index  FLOORSMAX_MODE\n",
      "0  205992             1.0\n",
      "1  165769             1.0\n",
      "2   21028             1.0\n",
      "3  129059             1.0\n",
      "4   94283             1.0\n",
      "5  111430             1.0\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "Column = LANDAREA_MODE, Mean = 0.06495768445653159, Min = 0.0, Max = 1.0\n",
      "    index  LANDAREA_MODE\n",
      "0   37937            0.0\n",
      "1   36653            0.0\n",
      "2   11685            0.0\n",
      "3  203921            0.0\n",
      "4  203932            0.0\n",
      "5   74872            0.0\n",
      "    index  LANDAREA_MODE\n",
      "0  219381            1.0\n",
      "1  239613            1.0\n",
      "2  275601            1.0\n",
      "3  192939            1.0\n",
      "4   38580            1.0\n",
      "5  250697            1.0\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "Column = LIVINGAREA_MODE, Mean = 0.10597505043676843, Min = 0.0, Max = 1.0\n",
      "    index  LIVINGAREA_MODE\n",
      "0  191648              0.0\n",
      "1   21601              0.0\n",
      "2  253488              0.0\n",
      "3  186336              0.0\n",
      "4  109908              0.0\n",
      "5    6759              0.0\n",
      "    index  LIVINGAREA_MODE\n",
      "0   94404              1.0\n",
      "1   70328              1.0\n",
      "2  301506              1.0\n",
      "3  107232              1.0\n",
      "4  267327              1.0\n",
      "5  169391              1.0\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "Column = NONLIVINGAREA_MODE, Mean = 0.027022319685907382, Min = 0.0, Max = 1.0\n",
      "    index  NONLIVINGAREA_MODE\n",
      "0       0                 0.0\n",
      "1  139194                 0.0\n",
      "2  139181                 0.0\n",
      "3  139180                 0.0\n",
      "4  139175                 0.0\n",
      "5  139170                 0.0\n",
      "    index  NONLIVINGAREA_MODE\n",
      "0    9975                 1.0\n",
      "1   85620                 1.0\n",
      "2  265060                 1.0\n",
      "3  252149                 1.0\n",
      "4   88688                 1.0\n",
      "5  127462                 1.0\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "Column = APARTMENTS_MEDI, Mean = 0.11784992076621098, Min = 0.0, Max = 1.0\n",
      "    index  APARTMENTS_MEDI\n",
      "0  289128              0.0\n",
      "1  174446              0.0\n",
      "2   52287              0.0\n",
      "3  305063              0.0\n",
      "4  133786              0.0\n",
      "5   22444              0.0\n",
      "    index  APARTMENTS_MEDI\n",
      "0  250471              1.0\n",
      "1   98298              1.0\n",
      "2  219261              1.0\n",
      "3   27263              1.0\n",
      "4  306206              1.0\n",
      "5  155677              1.0\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "Column = BASEMENTAREA_MEDI, Mean = 0.08795485466559964, Min = 0.0, Max = 1.0\n",
      "    index  BASEMENTAREA_MEDI\n",
      "0  167070                0.0\n",
      "1   15481                0.0\n",
      "2  149487                0.0\n",
      "3  149516                0.0\n",
      "4  149520                0.0\n",
      "5  149521                0.0\n",
      "    index  BASEMENTAREA_MEDI\n",
      "0  245562                1.0\n",
      "1   67838                1.0\n",
      "2   42425                1.0\n",
      "3   78473                1.0\n",
      "4   81809                1.0\n",
      "5  195260                1.0\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "Column = YEARS_BEGINEXPLUATATION_MEDI, Mean = 0.9777522640679884, Min = 0.0, Max = 1.0\n",
      "    index  YEARS_BEGINEXPLUATATION_MEDI\n",
      "0  274934                           0.0\n",
      "1   64604                           0.0\n",
      "2   27023                           0.0\n",
      "3   74304                           0.0\n",
      "4  151393                           0.0\n",
      "5  134311                           0.0\n",
      "    index  YEARS_BEGINEXPLUATATION_MEDI\n",
      "0  131083                           1.0\n",
      "1  288193                           1.0\n",
      "2   68812                           1.0\n",
      "3  131061                           1.0\n",
      "4   46373                           1.0\n",
      "5   58383                           1.0\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "Column = ELEVATORS_MEDI, Mean = 0.07807784431138909, Min = 0.0, Max = 1.0\n",
      "    index  ELEVATORS_MEDI\n",
      "0       0             0.0\n",
      "1  147124             0.0\n",
      "2  147122             0.0\n",
      "3  147121             0.0\n",
      "4  147119             0.0\n",
      "5  147116             0.0\n",
      "    index  ELEVATORS_MEDI\n",
      "0  272848             1.0\n",
      "1  223513             1.0\n",
      "2  262679             1.0\n",
      "3  297171             1.0\n",
      "4    9975             1.0\n",
      "5  157684             1.0\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "Column = ENTRANCES_MEDI, Mean = 0.14921278072889435, Min = 0.0, Max = 1.0\n",
      "    index  ENTRANCES_MEDI\n",
      "0  112258             0.0\n",
      "1   45093             0.0\n",
      "2  117977             0.0\n",
      "3  160158             0.0\n",
      "4   93671             0.0\n",
      "5  287728             0.0\n",
      "    index  ENTRANCES_MEDI\n",
      "0  269632             1.0\n",
      "1  256431             1.0\n",
      "2  220302             1.0\n",
      "3  119265             1.0\n",
      "4   61129             1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5   92250             1.0\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "Column = FLOORSMAX_MEDI, Mean = 0.22589659009237328, Min = 0.0, Max = 1.0\n",
      "    index  FLOORSMAX_MEDI\n",
      "0  203520             0.0\n",
      "1  153291             0.0\n",
      "2   19198             0.0\n",
      "3  217146             0.0\n",
      "4   19193             0.0\n",
      "5  173737             0.0\n",
      "    index  FLOORSMAX_MEDI\n",
      "0  163566             1.0\n",
      "1  141185             1.0\n",
      "2    1586             1.0\n",
      "3  281600             1.0\n",
      "4  221202             1.0\n",
      "5   71519             1.0\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "Column = LANDAREA_MEDI, Mean = 0.06716874904930549, Min = 0.0, Max = 1.0\n",
      "    index  LANDAREA_MEDI\n",
      "0  192728            0.0\n",
      "1  243136            0.0\n",
      "2  243140            0.0\n",
      "3  243147            0.0\n",
      "4  130531            0.0\n",
      "5  130492            0.0\n",
      "    index  LANDAREA_MEDI\n",
      "0  259714            1.0\n",
      "1  183250            1.0\n",
      "2  275601            1.0\n",
      "3   38580            1.0\n",
      "4  179494            1.0\n",
      "5  185561            1.0\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "Column = LIVINGAREA_MEDI, Mean = 0.10860673604881217, Min = 0.0, Max = 1.0\n",
      "    index  LIVINGAREA_MEDI\n",
      "0  132325              0.0\n",
      "1  248659              0.0\n",
      "2  125321              0.0\n",
      "3  181405              0.0\n",
      "4  290998              0.0\n",
      "5   85220              0.0\n",
      "    index  LIVINGAREA_MEDI\n",
      "0  214779              1.0\n",
      "1  122424              1.0\n",
      "2   67714              1.0\n",
      "3  177605              1.0\n",
      "4  292505              1.0\n",
      "5  107232              1.0\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "Column = NONLIVINGAREA_MEDI, Mean = 0.028235920597341983, Min = 0.0, Max = 1.0\n",
      "    index  NONLIVINGAREA_MEDI\n",
      "0       0                 0.0\n",
      "1  136214                 0.0\n",
      "2  136205                 0.0\n",
      "3  136203                 0.0\n",
      "4  136200                 0.0\n",
      "5  136178                 0.0\n",
      "    index  NONLIVINGAREA_MEDI\n",
      "0   90872                 1.0\n",
      "1   98466                 1.0\n",
      "2   94404                 1.0\n",
      "3  133659                 1.0\n",
      "4   56833                 1.0\n",
      "5   59656                 1.0\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "Column = TOTALAREA_MODE, Mean = 0.10254666268534579, Min = 0.0, Max = 1.0\n",
      "    index  TOTALAREA_MODE\n",
      "0   51388             0.0\n",
      "1   27831             0.0\n",
      "2   16251             0.0\n",
      "3   52099             0.0\n",
      "4   27897             0.0\n",
      "5  170058             0.0\n",
      "    index  TOTALAREA_MODE\n",
      "0  224154             1.0\n",
      "1   80849             1.0\n",
      "2   14143             1.0\n",
      "3  277020             1.0\n",
      "4   74135             1.0\n",
      "5  306206             1.0\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "Column = OBS_30_CNT_SOCIAL_CIRCLE, Mean = 1.4222454239942892, Min = 0.0, Max = 348.0\n",
      "    index  OBS_30_CNT_SOCIAL_CIRCLE\n",
      "0  307510                       0.0\n",
      "1  254704                       0.0\n",
      "2  254702                       0.0\n",
      "3  136736                       0.0\n",
      "4  136737                       0.0\n",
      "5  136738                       0.0\n",
      "    index  OBS_30_CNT_SOCIAL_CIRCLE\n",
      "0   33480                      28.0\n",
      "1   56170                      29.0\n",
      "2  169517                      30.0\n",
      "3  280641                      30.0\n",
      "4   77497                      47.0\n",
      "5  148403                     348.0\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "Column = DEF_30_CNT_SOCIAL_CIRCLE, Mean = 0.1434206662533827, Min = 0.0, Max = 34.0\n",
      "    index  DEF_30_CNT_SOCIAL_CIRCLE\n",
      "0  153755                       0.0\n",
      "1  198662                       0.0\n",
      "2  198663                       0.0\n",
      "3  198664                       0.0\n",
      "4  198665                       0.0\n",
      "5  198666                       0.0\n",
      "    index  DEF_30_CNT_SOCIAL_CIRCLE\n",
      "0  224433                       6.0\n",
      "1  298686                       6.0\n",
      "2  152554                       6.0\n",
      "3  133829                       7.0\n",
      "4  198047                       8.0\n",
      "5  148403                      34.0\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "Column = OBS_60_CNT_SOCIAL_CIRCLE, Mean = 1.4052921791902133, Min = 0.0, Max = 344.0\n",
      "    index  OBS_60_CNT_SOCIAL_CIRCLE\n",
      "0  307510                       0.0\n",
      "1  137219                       0.0\n",
      "2  137221                       0.0\n",
      "3  137224                       0.0\n",
      "4  137226                       0.0\n",
      "5  137228                       0.0\n",
      "    index  OBS_60_CNT_SOCIAL_CIRCLE\n",
      "0   33480                      28.0\n",
      "1  280641                      29.0\n",
      "2   56170                      29.0\n",
      "3  169517                      30.0\n",
      "4   77497                      47.0\n",
      "5  148403                     344.0\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "Column = DEF_60_CNT_SOCIAL_CIRCLE, Mean = 0.10004894123788487, Min = 0.0, Max = 24.0\n",
      "    index  DEF_60_CNT_SOCIAL_CIRCLE\n",
      "0  153755                       0.0\n",
      "1  200344                       0.0\n",
      "2  200345                       0.0\n",
      "3  200346                       0.0\n",
      "4  200347                       0.0\n",
      "5  200348                       0.0\n",
      "    index  DEF_60_CNT_SOCIAL_CIRCLE\n",
      "0  279489                       5.0\n",
      "1  279348                       6.0\n",
      "2  198047                       6.0\n",
      "3  298686                       6.0\n",
      "4  133829                       7.0\n",
      "5  148403                      24.0\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "Column = DAYS_LAST_PHONE_CHANGE, Mean = -962.8587883320869, Min = -4292.0, Max = 0.0\n",
      "    index  DAYS_LAST_PHONE_CHANGE\n",
      "0  191568                 -4292.0\n",
      "1  137198                 -4185.0\n",
      "2  294270                 -4173.0\n",
      "3  101177                 -4153.0\n",
      "4  106063                 -4131.0\n",
      "5  156299                 -4128.0\n",
      "    index  DAYS_LAST_PHONE_CHANGE\n",
      "0  225133                     0.0\n",
      "1  225124                     0.0\n",
      "2   55202                     0.0\n",
      "3   18319                     0.0\n",
      "4  225143                     0.0\n",
      "5  150104                     0.0\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "Column = AMT_REQ_CREDIT_BUREAU_HOUR, Mean = 0.0064024481939340665, Min = 0.0, Max = 4.0\n",
      "    index  AMT_REQ_CREDIT_BUREAU_HOUR\n",
      "0       0                         0.0\n",
      "1  197265                         0.0\n",
      "2  197266                         0.0\n",
      "3  197267                         0.0\n",
      "4  197268                         0.0\n",
      "5  197269                         0.0\n",
      "    index  AMT_REQ_CREDIT_BUREAU_HOUR\n",
      "0  187365                         3.0\n",
      "1  261186                         3.0\n",
      "2  110127                         3.0\n",
      "3   72054                         3.0\n",
      "4   91374                         3.0\n",
      "5  153915                         4.0\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "Column = AMT_REQ_CREDIT_BUREAU_DAY, Mean = 0.007000210532644792, Min = 0.0, Max = 9.0\n",
      "    index  AMT_REQ_CREDIT_BUREAU_DAY\n",
      "0       0                        0.0\n",
      "1  197309                        0.0\n",
      "2  197310                        0.0\n",
      "3  197311                        0.0\n",
      "4  197313                        0.0\n",
      "5  197314                        0.0\n",
      "    index  AMT_REQ_CREDIT_BUREAU_DAY\n",
      "0  238129                        6.0\n",
      "1  165196                        6.0\n",
      "2  204001                        6.0\n",
      "3  126946                        8.0\n",
      "4  126468                        9.0\n",
      "5  110127                        9.0\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "Column = AMT_REQ_CREDIT_BUREAU_WEEK, Mean = 0.03436193569730462, Min = 0.0, Max = 8.0\n",
      "    index  AMT_REQ_CREDIT_BUREAU_WEEK\n",
      "0       0                         0.0\n",
      "1  195882                         0.0\n",
      "2  195883                         0.0\n",
      "3  195884                         0.0\n",
      "4  195885                         0.0\n",
      "5  195886                         0.0\n",
      "    index  AMT_REQ_CREDIT_BUREAU_WEEK\n",
      "0  200509                         7.0\n",
      "1  253237                         8.0\n",
      "2  178835                         8.0\n",
      "3  126468                         8.0\n",
      "4  292966                         8.0\n",
      "5   87374                         8.0\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "Column = AMT_REQ_CREDIT_BUREAU_MON, Mean = 0.26739526000773584, Min = 0.0, Max = 27.0\n",
      "    index  AMT_REQ_CREDIT_BUREAU_MON\n",
      "0       0                        0.0\n",
      "1  170223                        0.0\n",
      "2  170224                        0.0\n",
      "3  170225                        0.0\n",
      "4  282437                        0.0\n",
      "5  170227                        0.0\n",
      "    index  AMT_REQ_CREDIT_BUREAU_MON\n",
      "0  235147                       19.0\n",
      "1   23241                       19.0\n",
      "2  266065                       22.0\n",
      "3   88209                       23.0\n",
      "4   12869                       24.0\n",
      "5  253488                       27.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "Column = AMT_REQ_CREDIT_BUREAU_QRT, Mean = 0.2654741495984415, Min = 0.0, Max = 261.0\n",
      "    index  AMT_REQ_CREDIT_BUREAU_QRT\n",
      "0       0                        0.0\n",
      "1  186952                        0.0\n",
      "2  186953                        0.0\n",
      "3  186954                        0.0\n",
      "4  186956                        0.0\n",
      "5  186957                        0.0\n",
      "    index  AMT_REQ_CREDIT_BUREAU_QRT\n",
      "0   16194                        8.0\n",
      "1  127569                        8.0\n",
      "2   62052                        8.0\n",
      "3  289714                        8.0\n",
      "4  253541                       19.0\n",
      "5  239474                      261.0\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "Column = AMT_REQ_CREDIT_BUREAU_YEAR, Mean = 1.8999744353227703, Min = 0.0, Max = 25.0\n",
      "    index  AMT_REQ_CREDIT_BUREAU_YEAR\n",
      "0  153755                         0.0\n",
      "1   66417                         0.0\n",
      "2   66416                         0.0\n",
      "3  191305                         0.0\n",
      "4  191306                         0.0\n",
      "5   66413                         0.0\n",
      "    index  AMT_REQ_CREDIT_BUREAU_YEAR\n",
      "0  173071                        19.0\n",
      "1  278398                        20.0\n",
      "2  132792                        21.0\n",
      "3   76655                        22.0\n",
      "4   29612                        23.0\n",
      "5   19824                        25.0\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "Column = SK_ID_CURR, Mean = 278180.51857657125, Min = 100002, Max = 456255\n",
      "   index  SK_ID_CURR\n",
      "0      0      100002\n",
      "1      1      100003\n",
      "2      2      100004\n",
      "3      3      100006\n",
      "4      4      100007\n",
      "5      5      100008\n",
      "    index  SK_ID_CURR\n",
      "0  307505      456249\n",
      "1  307506      456251\n",
      "2  307507      456252\n",
      "3  307508      456253\n",
      "4  307509      456254\n",
      "5  307510      456255\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "Column = CNT_CHILDREN, Mean = 0.4170517477423572, Min = 0, Max = 19\n",
      "    index  CNT_CHILDREN\n",
      "0       0             0\n",
      "1  186892             0\n",
      "2  186893             0\n",
      "3  186894             0\n",
      "4  186895             0\n",
      "5  186897             0\n",
      "    index  CNT_CHILDREN\n",
      "0   80948            12\n",
      "1  176011            14\n",
      "2  183878            14\n",
      "3  267998            14\n",
      "4  155369            19\n",
      "5  265784            19\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "Column = DAYS_BIRTH, Mean = -16036.995066843137, Min = -25229, Max = -7489\n",
      "    index  DAYS_BIRTH\n",
      "0  265026      -25229\n",
      "1  124430      -25201\n",
      "2   63316      -25201\n",
      "3  143266      -25200\n",
      "4  130108      -25197\n",
      "5  169562      -25197\n",
      "    index  DAYS_BIRTH\n",
      "0  173803       -7678\n",
      "1  137182       -7678\n",
      "2  170384       -7676\n",
      "3   53702       -7676\n",
      "4  168135       -7673\n",
      "5  235444       -7489\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "Column = DAYS_EMPLOYED, Mean = 63815.04590404896, Min = -17912, Max = 365243\n",
      "    index  DAYS_EMPLOYED\n",
      "0  280994         -17912\n",
      "1  273069         -17583\n",
      "2  208899         -17546\n",
      "3   35191         -17531\n",
      "4  234168         -17522\n",
      "5  142446         -17170\n",
      "    index  DAYS_EMPLOYED\n",
      "0   72066         365243\n",
      "1  268782         365243\n",
      "2   72057         365243\n",
      "3   72056         365243\n",
      "4  268773         365243\n",
      "5  253780         365243\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "Column = DAYS_ID_PUBLISH, Mean = -2994.2023732484367, Min = -7197, Max = 0\n",
      "    index  DAYS_ID_PUBLISH\n",
      "0  128073            -7197\n",
      "1  139387            -6551\n",
      "2  167492            -6383\n",
      "3  111706            -6337\n",
      "4  175941            -6274\n",
      "5   62092            -6265\n",
      "    index  DAYS_ID_PUBLISH\n",
      "0   83401                0\n",
      "1   20354                0\n",
      "2  149817                0\n",
      "3  251874                0\n",
      "4   86452                0\n",
      "5  243336                0\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "Column = FLAG_MOBIL, Mean = 0.9999967480838083, Min = 0, Max = 1\n",
      "    index  FLAG_MOBIL\n",
      "0   15709           0\n",
      "1  205012           1\n",
      "2  205011           1\n",
      "3  205010           1\n",
      "4  205009           1\n",
      "5  205008           1\n",
      "    index  FLAG_MOBIL\n",
      "0  102502           1\n",
      "1  102501           1\n",
      "2  102500           1\n",
      "3  102499           1\n",
      "4  102497           1\n",
      "5  307510           1\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "Column = FLAG_EMP_PHONE, Mean = 0.8198893698111612, Min = 0, Max = 1\n",
      "    index  FLAG_EMP_PHONE\n",
      "0  168916               0\n",
      "1  129895               0\n",
      "2  260014               0\n",
      "3  129889               0\n",
      "4  260012               0\n",
      "5  200996               0\n",
      "    index  FLAG_EMP_PHONE\n",
      "0  112605               1\n",
      "1  112606               1\n",
      "2  112608               1\n",
      "3  112609               1\n",
      "4  112594               1\n",
      "5  307510               1\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "Column = FLAG_WORK_PHONE, Mean = 0.1993684778755882, Min = 0, Max = 1\n",
      "    index  FLAG_WORK_PHONE\n",
      "0       0                0\n",
      "1  193649                0\n",
      "2  193650                0\n",
      "3  193651                0\n",
      "4  193652                0\n",
      "5  193654                0\n",
      "    index  FLAG_WORK_PHONE\n",
      "0   48281                1\n",
      "1   48282                1\n",
      "2  105732                1\n",
      "3   48285                1\n",
      "4  105730                1\n",
      "5  307510                1\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "Column = FLAG_CONT_MOBILE, Mean = 0.9981334001060125, Min = 0, Max = 1\n",
      "    index  FLAG_CONT_MOBILE\n",
      "0  128440                 0\n",
      "1  148382                 0\n",
      "2  156179                 0\n",
      "3  303998                 0\n",
      "4   75331                 0\n",
      "5  262961                 0\n",
      "    index  FLAG_CONT_MOBILE\n",
      "0  102608                 1\n",
      "1  102607                 1\n",
      "2  102606                 1\n",
      "3  102605                 1\n",
      "4  102603                 1\n",
      "5  307510                 1\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "Column = FLAG_PHONE, Mean = 0.28106636835755466, Min = 0, Max = 1\n",
      "    index  FLAG_PHONE\n",
      "0  153755           0\n",
      "1  263619           0\n",
      "2  263618           0\n",
      "3  156661           0\n",
      "4  156662           0\n",
      "5  156663           0\n",
      "    index  FLAG_PHONE\n",
      "0  160311           1\n",
      "1  160302           1\n",
      "2  160296           1\n",
      "3  160286           1\n",
      "4  160279           1\n",
      "5  307510           1\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "Column = FLAG_EMAIL, Mean = 0.0567199222141647, Min = 0, Max = 1\n",
      "    index  FLAG_EMAIL\n",
      "0       0           0\n",
      "1  202080           0\n",
      "2  202079           0\n",
      "3  202078           0\n",
      "4  202077           0\n",
      "5  202075           0\n",
      "    index  FLAG_EMAIL\n",
      "0   94697           1\n",
      "1  129258           1\n",
      "2  283722           1\n",
      "3   94712           1\n",
      "4  242663           1\n",
      "5  186598           1\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "Column = REGION_RATING_CLIENT, Mean = 2.0524631639193394, Min = 1, Max = 3\n",
      "    index  REGION_RATING_CLIENT\n",
      "0  307510                     1\n",
      "1  261682                     1\n",
      "2  261677                     1\n",
      "3  261675                     1\n",
      "4  184954                     1\n",
      "5  184955                     1\n",
      "    index  REGION_RATING_CLIENT\n",
      "0  255082                     3\n",
      "1  185729                     3\n",
      "2  185728                     3\n",
      "3   49360                     3\n",
      "4  185742                     3\n",
      "5  228369                     3\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "Column = REGION_RATING_CLIENT_W_CITY, Mean = 2.031520823645333, Min = 1, Max = 3\n",
      "    index  REGION_RATING_CLIENT_W_CITY\n",
      "0  307510                            1\n",
      "1  236188                            1\n",
      "2  236187                            1\n",
      "3   68799                            1\n",
      "4  236165                            1\n",
      "5  236160                            1\n",
      "    index  REGION_RATING_CLIENT_W_CITY\n",
      "0  232685                            3\n",
      "1   72211                            3\n",
      "2  232694                            3\n",
      "3   72196                            3\n",
      "4  232663                            3\n",
      "5   75518                            3\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "Column = HOUR_APPR_PROCESS_START, Mean = 12.063418869568894, Min = 0, Max = 23\n",
      "    index  HOUR_APPR_PROCESS_START\n",
      "0  203613                        0\n",
      "1  242423                        0\n",
      "2  165358                        0\n",
      "3  139899                        0\n",
      "4  213430                        0\n",
      "5  251294                        0\n",
      "    index  HOUR_APPR_PROCESS_START\n",
      "0   24268                       23\n",
      "1   52302                       23\n",
      "2  240953                       23\n",
      "3  245876                       23\n",
      "4  147502                       23\n",
      "5   98955                       23\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "Column = REG_REGION_NOT_LIVE_REGION, Mean = 0.015144173704355291, Min = 0, Max = 1\n",
      "    index  REG_REGION_NOT_LIVE_REGION\n",
      "0       0                           0\n",
      "1  204252                           0\n",
      "2  204251                           0\n",
      "3  204250                           0\n",
      "4  204249                           0\n",
      "5  204248                           0\n",
      "    index  REG_REGION_NOT_LIVE_REGION\n",
      "0   16384                           1\n",
      "1  158585                           1\n",
      "2   71728                           1\n",
      "3  146648                           1\n",
      "4  205385                           1\n",
      "5  146842                           1\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "Column = REG_REGION_NOT_WORK_REGION, Mean = 0.05076891558350758, Min = 0, Max = 1\n",
      "    index  REG_REGION_NOT_WORK_REGION\n",
      "0       0                           0\n",
      "1  202407                           0\n",
      "2  202406                           0\n",
      "3  202405                           0\n",
      "4  202404                           0\n",
      "5  202403                           0\n",
      "    index  REG_REGION_NOT_WORK_REGION\n",
      "0   21778                           1\n",
      "1   94720                           1\n",
      "2  284526                           1\n",
      "3   61104                           1\n",
      "4   94725                           1\n",
      "5   78775                           1\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "Column = LIVE_REGION_NOT_WORK_REGION, Mean = 0.04065870814377372, Min = 0, Max = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    index  LIVE_REGION_NOT_WORK_REGION\n",
      "0       0                            0\n",
      "1  202901                            0\n",
      "2  202900                            0\n",
      "3  202899                            0\n",
      "4  202898                            0\n",
      "5  202897                            0\n",
      "    index  LIVE_REGION_NOT_WORK_REGION\n",
      "0  293421                            1\n",
      "1  138074                            1\n",
      "2  181962                            1\n",
      "3  273387                            1\n",
      "4   13483                            1\n",
      "5  150516                            1\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "Column = REG_CITY_NOT_LIVE_CITY, Mean = 0.07817281333025486, Min = 0, Max = 1\n",
      "    index  REG_CITY_NOT_LIVE_CITY\n",
      "0       0                       0\n",
      "1  200879                       0\n",
      "2  200878                       0\n",
      "3  200877                       0\n",
      "4  200876                       0\n",
      "5  200875                       0\n",
      "    index  REG_CITY_NOT_LIVE_CITY\n",
      "0  280000                       1\n",
      "1  279999                       1\n",
      "2  279998                       1\n",
      "3  240757                       1\n",
      "4  280018                       1\n",
      "5   23227                       1\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "Column = REG_CITY_NOT_WORK_CITY, Mean = 0.23045354475124466, Min = 0, Max = 1\n",
      "    index  REG_CITY_NOT_WORK_CITY\n",
      "0       0                       0\n",
      "1  191793                       0\n",
      "2  191794                       0\n",
      "3  191796                       0\n",
      "4  191797                       0\n",
      "5  191798                       0\n",
      "    index  REG_CITY_NOT_WORK_CITY\n",
      "0  242603                       1\n",
      "1  104372                       1\n",
      "2  242601                       1\n",
      "3  242600                       1\n",
      "4  242597                       1\n",
      "5  307510                       1\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "Column = LIVE_CITY_NOT_WORK_CITY, Mean = 0.17955455252007246, Min = 0, Max = 1\n",
      "    index  LIVE_CITY_NOT_WORK_CITY\n",
      "0       0                        0\n",
      "1  194925                        0\n",
      "2  194926                        0\n",
      "3  194927                        0\n",
      "4  194928                        0\n",
      "5  194929                        0\n",
      "    index  LIVE_CITY_NOT_WORK_CITY\n",
      "0   69023                        1\n",
      "1  223394                        1\n",
      "2  223391                        1\n",
      "3  223383                        1\n",
      "4  223438                        1\n",
      "5  307510                        1\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "Column = FLAG_DOCUMENT_2, Mean = 4.2274910491006824e-05, Min = 0, Max = 1\n",
      "    index  FLAG_DOCUMENT_2\n",
      "0       0                0\n",
      "1  205008                0\n",
      "2  205007                0\n",
      "3  205006                0\n",
      "4  205005                0\n",
      "5  205004                0\n",
      "    index  FLAG_DOCUMENT_2\n",
      "0  187327                1\n",
      "1   33976                1\n",
      "2  109258                1\n",
      "3  282657                1\n",
      "4   79252                1\n",
      "5   98999                1\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "Column = FLAG_DOCUMENT_3, Mean = 0.7100233812774177, Min = 0, Max = 1\n",
      "    index  FLAG_DOCUMENT_3\n",
      "0   89851                0\n",
      "1   99875                0\n",
      "2  236384                0\n",
      "3   99870                0\n",
      "4   99869                0\n",
      "5   99867                0\n",
      "    index  FLAG_DOCUMENT_3\n",
      "0  119752                1\n",
      "1  119755                1\n",
      "2  119756                1\n",
      "3  119757                1\n",
      "4  119738                1\n",
      "5  307510                1\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "Column = FLAG_DOCUMENT_4, Mean = 8.129790479039775e-05, Min = 0, Max = 1\n",
      "    index  FLAG_DOCUMENT_4\n",
      "0       0                0\n",
      "1  205007                0\n",
      "2  205006                0\n",
      "3  205005                0\n",
      "4  205004                0\n",
      "5  205003                0\n",
      "    index  FLAG_DOCUMENT_4\n",
      "0    6928                1\n",
      "1   99378                1\n",
      "2  119245                1\n",
      "3   18890                1\n",
      "4   71348                1\n",
      "5   29787                1\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "Column = FLAG_DOCUMENT_5, Mean = 0.015114906458630749, Min = 0, Max = 1\n",
      "    index  FLAG_DOCUMENT_5\n",
      "0       0                0\n",
      "1  204244                0\n",
      "2  204243                0\n",
      "3  204242                0\n",
      "4  204241                0\n",
      "5  204240                0\n",
      "    index  FLAG_DOCUMENT_5\n",
      "0  223140                1\n",
      "1   16341                1\n",
      "2   53529                1\n",
      "3  100714                1\n",
      "4   71721                1\n",
      "5  109106                1\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "Column = FLAG_DOCUMENT_6, Mean = 0.0880553866365756, Min = 0, Max = 1\n",
      "    index  FLAG_DOCUMENT_6\n",
      "0       0                0\n",
      "1  200295                0\n",
      "2  200296                0\n",
      "3  200297                0\n",
      "4  200298                0\n",
      "5  200299                0\n",
      "    index  FLAG_DOCUMENT_6\n",
      "0  285682                1\n",
      "1  285681                1\n",
      "2   37778                1\n",
      "3  266118                1\n",
      "4   37782                1\n",
      "5  183206                1\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "Column = FLAG_DOCUMENT_7, Mean = 0.00019186305530533867, Min = 0, Max = 1\n",
      "    index  FLAG_DOCUMENT_7\n",
      "0       0                0\n",
      "1  205008                0\n",
      "2  205007                0\n",
      "3  205006                0\n",
      "4  205005                0\n",
      "5  205004                0\n",
      "    index  FLAG_DOCUMENT_7\n",
      "0   90425                1\n",
      "1  141665                1\n",
      "2  124436                1\n",
      "3  180200                1\n",
      "4  157113                1\n",
      "5  160431                1\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "Column = FLAG_DOCUMENT_8, Mean = 0.08137595077899652, Min = 0, Max = 1\n",
      "    index  FLAG_DOCUMENT_8\n",
      "0       0                0\n",
      "1  200655                0\n",
      "2  200656                0\n",
      "3  200657                0\n",
      "4  200658                0\n",
      "5  200659                0\n",
      "    index  FLAG_DOCUMENT_8\n",
      "0   25911                1\n",
      "1  171010                1\n",
      "2   61397                1\n",
      "3   61396                1\n",
      "4   61390                1\n",
      "5   73605                1\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "Column = FLAG_DOCUMENT_9, Mean = 0.00389579559755586, Min = 0, Max = 1\n",
      "    index  FLAG_DOCUMENT_9\n",
      "0       0                0\n",
      "1  204804                0\n",
      "2  204803                0\n",
      "3  204802                0\n",
      "4  204801                0\n",
      "5  204800                0\n",
      "    index  FLAG_DOCUMENT_9\n",
      "0   30974                1\n",
      "1   43086                1\n",
      "2  214998                1\n",
      "3    4503                1\n",
      "4  134932                1\n",
      "5  198223                1\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "Column = FLAG_DOCUMENT_10, Mean = 2.276341334131137e-05, Min = 0, Max = 1\n",
      "    index  FLAG_DOCUMENT_10\n",
      "0       0                 0\n",
      "1  205011                 0\n",
      "2  205010                 0\n",
      "3  205009                 0\n",
      "4  205008                 0\n",
      "5  205007                 0\n",
      "    index  FLAG_DOCUMENT_10\n",
      "0  169324                 1\n",
      "1  107774                 1\n",
      "2  155351                 1\n",
      "3   60622                 1\n",
      "4   28723                 1\n",
      "5  266339                 1\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "Column = FLAG_DOCUMENT_11, Mean = 0.003912055178513939, Min = 0, Max = 1\n",
      "    index  FLAG_DOCUMENT_11\n",
      "0       0                 0\n",
      "1  204798                 0\n",
      "2  204797                 0\n",
      "3  204796                 0\n",
      "4  204795                 0\n",
      "5  204794                 0\n",
      "    index  FLAG_DOCUMENT_11\n",
      "0  251897                 1\n",
      "1  295210                 1\n",
      "2   98518                 1\n",
      "3   36358                 1\n",
      "4  117374                 1\n",
      "5   62299                 1\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "Column = FLAG_DOCUMENT_12, Mean = 6.503832383231819e-06, Min = 0, Max = 1\n",
      "    index  FLAG_DOCUMENT_12\n",
      "0       0                 0\n",
      "1  205011                 0\n",
      "2  205010                 0\n",
      "3  205009                 0\n",
      "4  205008                 0\n",
      "5  205007                 0\n",
      "    index  FLAG_DOCUMENT_12\n",
      "0  102502                 0\n",
      "1  102501                 0\n",
      "2  102499                 0\n",
      "3  307510                 0\n",
      "4  184660                 1\n",
      "5   50134                 1\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "Column = FLAG_DOCUMENT_13, Mean = 0.003525077151711646, Min = 0, Max = 1\n",
      "    index  FLAG_DOCUMENT_13\n",
      "0       0                 0\n",
      "1  204828                 0\n",
      "2  204827                 0\n",
      "3  204826                 0\n",
      "4  204825                 0\n",
      "5  204824                 0\n",
      "    index  FLAG_DOCUMENT_13\n",
      "0   80428                 1\n",
      "1  184343                 1\n",
      "2  269623                 1\n",
      "3   95301                 1\n",
      "4  167378                 1\n",
      "5   63190                 1\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "Column = FLAG_DOCUMENT_14, Mean = 0.0029364803210291664, Min = 0, Max = 1\n",
      "    index  FLAG_DOCUMENT_14\n",
      "0       0                 0\n",
      "1  204861                 0\n",
      "2  204860                 0\n",
      "3  204859                 0\n",
      "4  204858                 0\n",
      "5  204857                 0\n",
      "    index  FLAG_DOCUMENT_14\n",
      "0  294291                 1\n",
      "1   26865                 1\n",
      "2  176855                 1\n",
      "3  190792                 1\n",
      "4    8761                 1\n",
      "5  224070                 1\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "Column = FLAG_DOCUMENT_15, Mean = 0.0012097128232811183, Min = 0, Max = 1\n",
      "    index  FLAG_DOCUMENT_15\n",
      "0       0                 0\n",
      "1  204954                 0\n",
      "2  204953                 0\n",
      "3  204952                 0\n",
      "4  204951                 0\n",
      "5  204950                 0\n",
      "    index  FLAG_DOCUMENT_15\n",
      "0  165510                 1\n",
      "1  188778                 1\n",
      "2  149108                 1\n",
      "3  175148                 1\n",
      "4   95112                 1\n",
      "5   37170                 1\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "Column = FLAG_DOCUMENT_16, Mean = 0.009928100133003373, Min = 0, Max = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    index  FLAG_DOCUMENT_16\n",
      "0       0                 0\n",
      "1  204512                 0\n",
      "2  204511                 0\n",
      "3  204510                 0\n",
      "4  204509                 0\n",
      "5  204508                 0\n",
      "    index  FLAG_DOCUMENT_16\n",
      "0    8567                 1\n",
      "1  111413                 1\n",
      "2  175888                 1\n",
      "3  199459                 1\n",
      "4   73979                 1\n",
      "5   49174                 1\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "Column = FLAG_DOCUMENT_17, Mean = 0.0002666571277125046, Min = 0, Max = 1\n",
      "    index  FLAG_DOCUMENT_17\n",
      "0       0                 0\n",
      "1  204994                 0\n",
      "2  204993                 0\n",
      "3  204992                 0\n",
      "4  204991                 0\n",
      "5  204990                 0\n",
      "    index  FLAG_DOCUMENT_17\n",
      "0  291609                 1\n",
      "1  132142                 1\n",
      "2  175671                 1\n",
      "3  267448                 1\n",
      "4  166350                 1\n",
      "5  249836                 1\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "Column = FLAG_DOCUMENT_18, Mean = 0.008129790479039774, Min = 0, Max = 1\n",
      "    index  FLAG_DOCUMENT_18\n",
      "0       0                 0\n",
      "1  204586                 0\n",
      "2  204585                 0\n",
      "3  204584                 0\n",
      "4  204582                 0\n",
      "5  204581                 0\n",
      "    index  FLAG_DOCUMENT_18\n",
      "0  107459                 1\n",
      "1  121888                 1\n",
      "2  184594                 1\n",
      "3  107454                 1\n",
      "4  161021                 1\n",
      "5  287746                 1\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "Column = FLAG_DOCUMENT_19, Mean = 0.0005951006630657115, Min = 0, Max = 1\n",
      "    index  FLAG_DOCUMENT_19\n",
      "0       0                 0\n",
      "1  204973                 0\n",
      "2  204972                 0\n",
      "3  204971                 0\n",
      "4  204970                 0\n",
      "5  204969                 0\n",
      "    index  FLAG_DOCUMENT_19\n",
      "0  155776                 1\n",
      "1  232216                 1\n",
      "2  263392                 1\n",
      "3   56501                 1\n",
      "4  300670                 1\n",
      "5  234201                 1\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "Column = FLAG_DOCUMENT_20, Mean = 0.0005072989258920819, Min = 0, Max = 1\n",
      "    index  FLAG_DOCUMENT_20\n",
      "0       0                 0\n",
      "1  204977                 0\n",
      "2  204976                 0\n",
      "3  204975                 0\n",
      "4  204974                 0\n",
      "5  204973                 0\n",
      "    index  FLAG_DOCUMENT_20\n",
      "0    4027                 1\n",
      "1  231730                 1\n",
      "2  199248                 1\n",
      "3  114693                 1\n",
      "4  218023                 1\n",
      "5  162863                 1\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "Column = FLAG_DOCUMENT_21, Mean = 0.0003349473677364387, Min = 0, Max = 1\n",
      "    index  FLAG_DOCUMENT_21\n",
      "0       0                 0\n",
      "1  204990                 0\n",
      "2  204989                 0\n",
      "3  204988                 0\n",
      "4  204987                 0\n",
      "5  204986                 0\n",
      "    index  FLAG_DOCUMENT_21\n",
      "0  235985                 1\n",
      "1   16567                 1\n",
      "2  168429                 1\n",
      "3  297000                 1\n",
      "4   14699                 1\n",
      "5  180483                 1\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n"
     ]
    }
   ],
   "source": [
    "for col in imputed_num_trainset.columns:\n",
    "    print('Column = {}, Mean = {}, Min = {}, Max = {}'.format(col, imputed_num_trainset[col].mean(), imputed_num_trainset[col].min(), imputed_num_trainset[col].max() ))\n",
    "    print(pd.DataFrame(imputed_num_trainset[col].sort_values().head(n=6)).reset_index()) \n",
    "    print(pd.DataFrame(imputed_num_trainset[col].sort_values().tail(n=6)).reset_index())\n",
    "    print ('_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _')\n",
    "\n",
    "# we retrieved data as new DF with col1 as original index value. This will help in referencing the right row for removing/imputing the outlier data later on. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - From above results we can infer that below listed columns can be considered to contain outliers and such data needs to be removed/imputed - \n",
    "\n",
    "- For index value = 148403, below columns may be considered as outliers. Since it is only 4 columns of the row containing 90+ cols, We can impute these with mode of respective column instead of removing the entire row. \n",
    "\n",
    "    1. Column = OBS_30_CNT_SOCIAL_CIRCLE   ;               \n",
    "       Column value  = 348.0; \n",
    "  \n",
    "    2. Column = DEF_30_CNT_SOCIAL_CIRCLE   ;               \n",
    "       Column value  = 34.0; \n",
    "\n",
    "    3. Column =   OBS_60_CNT_SOCIAL_CIRCLE   ;             \n",
    "       Column value  = 344.0; \n",
    "\n",
    "    4. Column = DEF_60_CNT_SOCIAL_CIRCLE    ;           \n",
    "       Column value  = 24.0; \n",
    "\n",
    "- We have one more outlier in a different index/row - \n",
    "    1. Column = AMT_REQ_CREDIT_BUREAU_QRT ;                 \n",
    "       Column value  = 261.0    ;               \n",
    "       index = 239474    ;               \n",
    "       use impute strategy = mean\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replaced value = 0.0\n",
      "median of column = OBS_30_CNT_SOCIAL_CIRCLE is 0.0\n",
      "\n",
      "\n",
      "0.0\n",
      "median of column = OBS_60_CNT_SOCIAL_CIRCLE is 0.0\n",
      "\n",
      "\n",
      "0.0\n",
      "mode of column = DEF_30_CNT_SOCIAL_CIRCLE is 0    0.0\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "0.0\n",
      "mode of column = DEF_60_CNT_SOCIAL_CIRCLE is 0    0.0\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "0.2654741495984415\n",
      "mean of column = AMT_REQ_CREDIT_BUREAU_QRT is 0.2646262627721174\n",
      "float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# use this to delete/remove rows where column value meets specified condition. \\nDataFrame.drop(index=<give row index>, columns=df[df[col_name == 1000]], axis=0, inplace=True) \\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# use this to impute outlier in row = index, column = col_name with mean of the column\n",
    " \n",
    "imputed_num_trainset.at[148403, 'OBS_30_CNT_SOCIAL_CIRCLE'] = imputed_num_trainset['OBS_30_CNT_SOCIAL_CIRCLE'].median()\n",
    "print ('replaced value = {}'.format(imputed_num_trainset.loc[148403, 'OBS_30_CNT_SOCIAL_CIRCLE']))\n",
    "print('median of column = {} is {}'.format('OBS_30_CNT_SOCIAL_CIRCLE', imputed_num_trainset['OBS_30_CNT_SOCIAL_CIRCLE'].median()))\n",
    "print('\\n')\n",
    "\n",
    "imputed_num_trainset.at[148403, 'OBS_60_CNT_SOCIAL_CIRCLE'] = imputed_num_trainset['OBS_60_CNT_SOCIAL_CIRCLE'].median()\n",
    "print (imputed_num_trainset.loc[148403, 'OBS_60_CNT_SOCIAL_CIRCLE'])\n",
    "print('median of column = {} is {}'.format('OBS_60_CNT_SOCIAL_CIRCLE', imputed_num_trainset['OBS_60_CNT_SOCIAL_CIRCLE'].median()))\n",
    "print('\\n')\n",
    "\n",
    "imputed_num_trainset.at[148403, 'DEF_30_CNT_SOCIAL_CIRCLE'] = imputed_num_trainset['DEF_30_CNT_SOCIAL_CIRCLE'].mode()\n",
    "print (imputed_num_trainset.loc[148403, 'DEF_30_CNT_SOCIAL_CIRCLE'])\n",
    "print('mode of column = {} is {}'.format('DEF_30_CNT_SOCIAL_CIRCLE', imputed_num_trainset['DEF_30_CNT_SOCIAL_CIRCLE'].mode()))\n",
    "print('\\n')\n",
    "\n",
    "imputed_num_trainset.at[148403, 'DEF_60_CNT_SOCIAL_CIRCLE'] = imputed_num_trainset['DEF_60_CNT_SOCIAL_CIRCLE'].mode()\n",
    "print (imputed_num_trainset.loc[148403, 'DEF_60_CNT_SOCIAL_CIRCLE'])\n",
    "print('mode of column = {} is {}'.format('DEF_60_CNT_SOCIAL_CIRCLE', imputed_num_trainset['DEF_60_CNT_SOCIAL_CIRCLE'].mode()))\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "imputed_num_trainset.at[239474, 'AMT_REQ_CREDIT_BUREAU_QRT'] = imputed_num_trainset['AMT_REQ_CREDIT_BUREAU_QRT'].mean()\n",
    "print (imputed_num_trainset.loc[239474, 'AMT_REQ_CREDIT_BUREAU_QRT'])\n",
    "print('mean of column = {} is {}'.format('AMT_REQ_CREDIT_BUREAU_QRT', imputed_num_trainset['AMT_REQ_CREDIT_BUREAU_QRT'].mean()))\n",
    "print(imputed_num_trainset['AMT_REQ_CREDIT_BUREAU_QRT'].dtype)\n",
    "\n",
    "'''\n",
    "# use this to delete/remove rows where column value meets specified condition. \n",
    "DataFrame.drop(index=<give row index>, columns=df[df[col_name == 1000]], axis=0, inplace=True) \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  - We shall let the testset outliers remain as-is to be a true reflection of realtime data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 3 : FEATURE EXTRACTION\n",
    "\n",
    "  - Perform one hot encoding for cat vars. \n",
    "  - Check for multi collinearity i.e. correlation between independent vars \n",
    "      Note: Random forest are not sensitive to multi collinearity. But Linear & Logistic regressions are. \n",
    "  - Calculate corr between independent vars & target var. Select the most positively correlated & most negatively correlated features with target vars.\n",
    "  - Instead of calculating correlations, we could use PCA (Principal Component Analysis) or t-SNE (t-distributed Stochastic Neighbor Embedding) algorithms to extract most relevant features. \n",
    "  - For now, we shall proceed with correlation. If performance of the model is too low, then we shall try out PCA/t-SNE\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  NAME_CONTRACT_TYPE CODE_GENDER FLAG_OWN_CAR FLAG_OWN_REALTY NAME_TYPE_SUITE  \\\n",
      "0         Cash loans           M            N               Y   Unaccompanied   \n",
      "1         Cash loans           F            N               N          Family   \n",
      "2    Revolving loans           M            Y               Y   Unaccompanied   \n",
      "3         Cash loans           F            N               Y   Unaccompanied   \n",
      "4         Cash loans           M            N               Y   Unaccompanied   \n",
      "\n",
      "  NAME_INCOME_TYPE            NAME_EDUCATION_TYPE    NAME_FAMILY_STATUS  \\\n",
      "0          Working  Secondary / secondary special  Single / not married   \n",
      "1    State servant               Higher education               Married   \n",
      "2          Working  Secondary / secondary special  Single / not married   \n",
      "3          Working  Secondary / secondary special        Civil marriage   \n",
      "4          Working  Secondary / secondary special  Single / not married   \n",
      "\n",
      "   NAME_HOUSING_TYPE OCCUPATION_TYPE WEEKDAY_APPR_PROCESS_START  \\\n",
      "0  House / apartment        Laborers                  WEDNESDAY   \n",
      "1  House / apartment      Core staff                     MONDAY   \n",
      "2  House / apartment        Laborers                     MONDAY   \n",
      "3  House / apartment        Laborers                  WEDNESDAY   \n",
      "4  House / apartment      Core staff                   THURSDAY   \n",
      "\n",
      "        ORGANIZATION_TYPE  HOUSETYPE_MODE WALLSMATERIAL_MODE  \\\n",
      "0  Business Entity Type 3  block of flats       Stone, brick   \n",
      "1                  School  block of flats              Block   \n",
      "2              Government  block of flats              Panel   \n",
      "3  Business Entity Type 3  block of flats              Panel   \n",
      "4                Religion  block of flats              Panel   \n",
      "\n",
      "  EMERGENCYSTATE_MODE  \n",
      "0                  No  \n",
      "1                  No  \n",
      "2                  No  \n",
      "3                  No  \n",
      "4                  No  \n",
      "\n",
      "\n",
      "  NAME_CONTRACT_TYPE CODE_GENDER FLAG_OWN_CAR FLAG_OWN_REALTY NAME_TYPE_SUITE  \\\n",
      "0         Cash loans           M            N               Y   Unaccompanied   \n",
      "1         Cash loans           F            N               N          Family   \n",
      "2    Revolving loans           M            Y               Y   Unaccompanied   \n",
      "3         Cash loans           F            N               Y   Unaccompanied   \n",
      "4         Cash loans           M            N               Y   Unaccompanied   \n",
      "\n",
      "  NAME_INCOME_TYPE            NAME_EDUCATION_TYPE    NAME_FAMILY_STATUS  \\\n",
      "0          Working  Secondary / secondary special  Single / not married   \n",
      "1    State servant               Higher education               Married   \n",
      "2          Working  Secondary / secondary special  Single / not married   \n",
      "3          Working  Secondary / secondary special        Civil marriage   \n",
      "4          Working  Secondary / secondary special  Single / not married   \n",
      "\n",
      "   NAME_HOUSING_TYPE OCCUPATION_TYPE WEEKDAY_APPR_PROCESS_START  \\\n",
      "0  House / apartment        Laborers                  WEDNESDAY   \n",
      "1  House / apartment      Core staff                     MONDAY   \n",
      "2  House / apartment        Laborers                     MONDAY   \n",
      "3  House / apartment        Laborers                  WEDNESDAY   \n",
      "4  House / apartment      Core staff                   THURSDAY   \n",
      "\n",
      "        ORGANIZATION_TYPE  HOUSETYPE_MODE WALLSMATERIAL_MODE  \\\n",
      "0  Business Entity Type 3  block of flats       Stone, brick   \n",
      "1                  School  block of flats              Block   \n",
      "2              Government  block of flats              Panel   \n",
      "3  Business Entity Type 3  block of flats              Panel   \n",
      "4                Religion  block of flats              Panel   \n",
      "\n",
      "  EMERGENCYSTATE_MODE  \n",
      "0                  No  \n",
      "1                  No  \n",
      "2                  No  \n",
      "3                  No  \n",
      "4                  No  \n"
     ]
    }
   ],
   "source": [
    "# categorical features before conversion to numeric form: \n",
    "\n",
    "backup_cat_train=imputed_cat_trainset\n",
    "backup_cat_test = imputed_cat_testset\n",
    "\n",
    "print(imputed_cat_trainset.head())\n",
    "print('\\n')\n",
    "print(backup_cat_train.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINSET CAT classes :\n",
      "Items in NAME_CONTRACT_TYPE: \n",
      "Cash loans         278232\n",
      "Revolving loans     29279\n",
      "Name: NAME_CONTRACT_TYPE, dtype: int64\n",
      "___________________________________\n",
      "Items in CODE_GENDER: \n",
      "F      202448\n",
      "M      105059\n",
      "XNA         4\n",
      "Name: CODE_GENDER, dtype: int64\n",
      "___________________________________\n",
      "Items in FLAG_OWN_CAR: \n",
      "N    202924\n",
      "Y    104587\n",
      "Name: FLAG_OWN_CAR, dtype: int64\n",
      "___________________________________\n",
      "Items in FLAG_OWN_REALTY: \n",
      "Y    213312\n",
      "N     94199\n",
      "Name: FLAG_OWN_REALTY, dtype: int64\n",
      "___________________________________\n",
      "Items in NAME_TYPE_SUITE: \n",
      "Unaccompanied      249818\n",
      "Family              40149\n",
      "Spouse, partner     11370\n",
      "Children             3267\n",
      "Other_B              1770\n",
      "Other_A               866\n",
      "Group of people       271\n",
      "Name: NAME_TYPE_SUITE, dtype: int64\n",
      "___________________________________\n",
      "Items in NAME_INCOME_TYPE: \n",
      "Working                 158774\n",
      "Commercial associate     71617\n",
      "Pensioner                55362\n",
      "State servant            21703\n",
      "Unemployed                  22\n",
      "Student                     18\n",
      "Businessman                 10\n",
      "Maternity leave              5\n",
      "Name: NAME_INCOME_TYPE, dtype: int64\n",
      "___________________________________\n",
      "Items in NAME_EDUCATION_TYPE: \n",
      "Secondary / secondary special    218391\n",
      "Higher education                  74863\n",
      "Incomplete higher                 10277\n",
      "Lower secondary                    3816\n",
      "Academic degree                     164\n",
      "Name: NAME_EDUCATION_TYPE, dtype: int64\n",
      "___________________________________\n",
      "Items in NAME_FAMILY_STATUS: \n",
      "Married                 196432\n",
      "Single / not married     45444\n",
      "Civil marriage           29775\n",
      "Separated                19770\n",
      "Widow                    16088\n",
      "Unknown                      2\n",
      "Name: NAME_FAMILY_STATUS, dtype: int64\n",
      "___________________________________\n",
      "Items in NAME_HOUSING_TYPE: \n",
      "House / apartment      272868\n",
      "With parents            14840\n",
      "Municipal apartment     11183\n",
      "Rented apartment         4881\n",
      "Office apartment         2617\n",
      "Co-op apartment          1122\n",
      "Name: NAME_HOUSING_TYPE, dtype: int64\n",
      "___________________________________\n",
      "Items in OCCUPATION_TYPE: \n",
      "Laborers                 151577\n",
      "Sales staff               32102\n",
      "Core staff                27570\n",
      "Managers                  21371\n",
      "Drivers                   18603\n",
      "High skill tech staff     11380\n",
      "Accountants                9813\n",
      "Medicine staff             8537\n",
      "Security staff             6721\n",
      "Cooking staff              5946\n",
      "Cleaning staff             4653\n",
      "Private service staff      2652\n",
      "Low-skill Laborers         2093\n",
      "Waiters/barmen staff       1348\n",
      "Secretaries                1305\n",
      "Realty agents               751\n",
      "HR staff                    563\n",
      "IT staff                    526\n",
      "Name: OCCUPATION_TYPE, dtype: int64\n",
      "___________________________________\n",
      "Items in WEEKDAY_APPR_PROCESS_START: \n",
      "TUESDAY      53901\n",
      "WEDNESDAY    51934\n",
      "MONDAY       50714\n",
      "THURSDAY     50591\n",
      "FRIDAY       50338\n",
      "SATURDAY     33852\n",
      "SUNDAY       16181\n",
      "Name: WEEKDAY_APPR_PROCESS_START, dtype: int64\n",
      "___________________________________\n",
      "Items in ORGANIZATION_TYPE: \n",
      "Business Entity Type 3    67992\n",
      "XNA                       55374\n",
      "Self-employed             38412\n",
      "Other                     16683\n",
      "Medicine                  11193\n",
      "Business Entity Type 2    10553\n",
      "Government                10404\n",
      "School                     8893\n",
      "Trade: type 7              7831\n",
      "Kindergarten               6880\n",
      "Construction               6721\n",
      "Business Entity Type 1     5984\n",
      "Transport: type 4          5398\n",
      "Trade: type 3              3492\n",
      "Industry: type 9           3368\n",
      "Industry: type 3           3278\n",
      "Security                   3247\n",
      "Housing                    2958\n",
      "Industry: type 11          2704\n",
      "Military                   2634\n",
      "Bank                       2507\n",
      "Agriculture                2454\n",
      "Police                     2341\n",
      "Transport: type 2          2204\n",
      "Postal                     2157\n",
      "Security Ministries        1974\n",
      "Trade: type 2              1900\n",
      "Restaurant                 1811\n",
      "Services                   1575\n",
      "University                 1327\n",
      "Industry: type 7           1307\n",
      "Transport: type 3          1187\n",
      "Industry: type 1           1039\n",
      "Hotel                       966\n",
      "Electricity                 950\n",
      "Industry: type 4            877\n",
      "Trade: type 6               631\n",
      "Industry: type 5            599\n",
      "Insurance                   597\n",
      "Telecom                     577\n",
      "Emergency                   560\n",
      "Industry: type 2            458\n",
      "Advertising                 429\n",
      "Realtor                     396\n",
      "Culture                     379\n",
      "Industry: type 12           369\n",
      "Trade: type 1               348\n",
      "Mobile                      317\n",
      "Legal Services              305\n",
      "Cleaning                    260\n",
      "Transport: type 1           201\n",
      "Industry: type 6            112\n",
      "Industry: type 10           109\n",
      "Religion                     85\n",
      "Industry: type 13            67\n",
      "Trade: type 4                64\n",
      "Trade: type 5                49\n",
      "Industry: type 8             24\n",
      "Name: ORGANIZATION_TYPE, dtype: int64\n",
      "___________________________________\n",
      "Items in HOUSETYPE_MODE: \n",
      "block of flats      304800\n",
      "specific housing      1499\n",
      "terraced house        1212\n",
      "Name: HOUSETYPE_MODE, dtype: int64\n",
      "___________________________________\n",
      "Items in WALLSMATERIAL_MODE: \n",
      "Panel           222381\n",
      "Stone, brick     64815\n",
      "Block             9253\n",
      "Wooden            5362\n",
      "Mixed             2296\n",
      "Monolithic        1779\n",
      "Others            1625\n",
      "Name: WALLSMATERIAL_MODE, dtype: int64\n",
      "___________________________________\n",
      "Items in EMERGENCYSTATE_MODE: \n",
      "No     305183\n",
      "Yes      2328\n",
      "Name: EMERGENCYSTATE_MODE, dtype: int64\n",
      "___________________________________\n"
     ]
    }
   ],
   "source": [
    "# check what are the various classes in each column of categorical set\n",
    "\n",
    "print('TRAINSET CAT classes :')\n",
    "for col in imputed_cat_trainset:\n",
    "    print('Items in ' + col + ': ')\n",
    "    print(imputed_cat_trainset[col].value_counts())\n",
    "    print('___________________________________')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTSET CAT classes :\n",
      "Items in NAME_CONTRACT_TYPE: \n",
      "Cash loans         48305\n",
      "Revolving loans      439\n",
      "Name: NAME_CONTRACT_TYPE, dtype: int64\n",
      "___________________________________\n",
      "Items in CODE_GENDER: \n",
      "F    32678\n",
      "M    16066\n",
      "Name: CODE_GENDER, dtype: int64\n",
      "___________________________________\n",
      "Items in FLAG_OWN_CAR: \n",
      "N    32311\n",
      "Y    16433\n",
      "Name: FLAG_OWN_CAR, dtype: int64\n",
      "___________________________________\n",
      "Items in FLAG_OWN_REALTY: \n",
      "Y    33658\n",
      "N    15086\n",
      "Name: FLAG_OWN_REALTY, dtype: int64\n",
      "___________________________________\n",
      "Items in NAME_TYPE_SUITE: \n",
      "Unaccompanied      40638\n",
      "Family              5881\n",
      "Spouse, partner     1448\n",
      "Children             408\n",
      "Other_B              211\n",
      "Other_A              109\n",
      "Group of people       49\n",
      "Name: NAME_TYPE_SUITE, dtype: int64\n",
      "___________________________________\n",
      "Items in NAME_INCOME_TYPE: \n",
      "Working                 24533\n",
      "Commercial associate    11402\n",
      "Pensioner                9273\n",
      "State servant            3532\n",
      "Student                     2\n",
      "Unemployed                  1\n",
      "Businessman                 1\n",
      "Name: NAME_INCOME_TYPE, dtype: int64\n",
      "___________________________________\n",
      "Items in NAME_EDUCATION_TYPE: \n",
      "Secondary / secondary special    33988\n",
      "Higher education                 12516\n",
      "Incomplete higher                 1724\n",
      "Lower secondary                    475\n",
      "Academic degree                     41\n",
      "Name: NAME_EDUCATION_TYPE, dtype: int64\n",
      "___________________________________\n",
      "Items in NAME_FAMILY_STATUS: \n",
      "Married                 32283\n",
      "Single / not married     7036\n",
      "Civil marriage           4261\n",
      "Separated                2955\n",
      "Widow                    2209\n",
      "Name: NAME_FAMILY_STATUS, dtype: int64\n",
      "___________________________________\n",
      "Items in NAME_HOUSING_TYPE: \n",
      "House / apartment      43645\n",
      "With parents            2234\n",
      "Municipal apartment     1617\n",
      "Rented apartment         718\n",
      "Office apartment         407\n",
      "Co-op apartment          123\n",
      "Name: NAME_HOUSING_TYPE, dtype: int64\n",
      "___________________________________\n",
      "Items in OCCUPATION_TYPE: \n",
      "Laborers                 24260\n",
      "Sales staff               5072\n",
      "Core staff                4361\n",
      "Managers                  3574\n",
      "Drivers                   2773\n",
      "High skill tech staff     1854\n",
      "Accountants               1628\n",
      "Medicine staff            1316\n",
      "Security staff             915\n",
      "Cooking staff              894\n",
      "Cleaning staff             656\n",
      "Private service staff      455\n",
      "Low-skill Laborers         272\n",
      "Secretaries                213\n",
      "Waiters/barmen staff       178\n",
      "Realty agents              138\n",
      "HR staff                   104\n",
      "IT staff                    81\n",
      "Name: OCCUPATION_TYPE, dtype: int64\n",
      "___________________________________\n",
      "Items in WEEKDAY_APPR_PROCESS_START: \n",
      "TUESDAY      9751\n",
      "WEDNESDAY    8457\n",
      "THURSDAY     8418\n",
      "MONDAY       8406\n",
      "FRIDAY       7250\n",
      "SATURDAY     4603\n",
      "SUNDAY       1859\n",
      "Name: WEEKDAY_APPR_PROCESS_START, dtype: int64\n",
      "___________________________________\n",
      "Items in ORGANIZATION_TYPE: \n",
      "Business Entity Type 3    10840\n",
      "XNA                        9274\n",
      "Self-employed              5920\n",
      "Other                      2707\n",
      "Medicine                   1716\n",
      "Government                 1508\n",
      "Business Entity Type 2     1479\n",
      "Trade: type 7              1303\n",
      "School                     1287\n",
      "Construction               1039\n",
      "Kindergarten               1038\n",
      "Business Entity Type 1      887\n",
      "Transport: type 4           884\n",
      "Trade: type 3               578\n",
      "Military                    530\n",
      "Industry: type 9            499\n",
      "Industry: type 3            489\n",
      "Security                    472\n",
      "Transport: type 2           448\n",
      "Police                      441\n",
      "Housing                     435\n",
      "Industry: type 11           416\n",
      "Bank                        374\n",
      "Security Ministries         341\n",
      "Services                    302\n",
      "Postal                      294\n",
      "Agriculture                 292\n",
      "Restaurant                  284\n",
      "Trade: type 2               242\n",
      "University                  221\n",
      "Industry: type 7            217\n",
      "Industry: type 1            178\n",
      "Transport: type 3           174\n",
      "Industry: type 4            167\n",
      "Electricity                 156\n",
      "Hotel                       134\n",
      "Trade: type 6               122\n",
      "Industry: type 5             97\n",
      "Telecom                      95\n",
      "Emergency                    91\n",
      "Insurance                    80\n",
      "Industry: type 12            77\n",
      "Industry: type 2             77\n",
      "Realtor                      72\n",
      "Advertising                  71\n",
      "Trade: type 1                64\n",
      "Culture                      61\n",
      "Legal Services               53\n",
      "Mobile                       45\n",
      "Cleaning                     43\n",
      "Transport: type 1            35\n",
      "Industry: type 6             27\n",
      "Industry: type 10            24\n",
      "Trade: type 4                14\n",
      "Religion                     12\n",
      "Trade: type 5                 9\n",
      "Industry: type 13             6\n",
      "Industry: type 8              3\n",
      "Name: ORGANIZATION_TYPE, dtype: int64\n",
      "___________________________________\n",
      "Items in HOUSETYPE_MODE: \n",
      "block of flats      48278\n",
      "specific housing      262\n",
      "terraced house        204\n",
      "Name: HOUSETYPE_MODE, dtype: int64\n",
      "___________________________________\n",
      "Items in WALLSMATERIAL_MODE: \n",
      "Panel           35162\n",
      "Stone, brick    10434\n",
      "Block            1428\n",
      "Wooden            794\n",
      "Mixed             353\n",
      "Monolithic        289\n",
      "Others            284\n",
      "Name: WALLSMATERIAL_MODE, dtype: int64\n",
      "___________________________________\n",
      "Items in EMERGENCYSTATE_MODE: \n",
      "No     48388\n",
      "Yes      356\n",
      "Name: EMERGENCYSTATE_MODE, dtype: int64\n",
      "___________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('TESTSET CAT classes :')\n",
    "for col in imputed_cat_testset:\n",
    "    print('Items in ' + col + ': ')\n",
    "    print(imputed_cat_testset[col].value_counts())\n",
    "    print('___________________________________')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OneHotEncoded Train shape = (307511, 136)\n",
      "OneHotEncoded Test shape = (48744, 133)\n"
     ]
    }
   ],
   "source": [
    "# Performing one hot encoding for other multi class categorical vars. \n",
    "# Note: sklearn suggests that one hot encoder takes less memory than label binarizer()\n",
    "\n",
    "\n",
    "OneHotEncoded_train_subset = pd.DataFrame()\n",
    "OneHotEncoded_test_subset = pd.DataFrame()\n",
    "\n",
    "\n",
    "OneHotEncoded_train_subset = pd.get_dummies(imputed_cat_trainset, columns = ['NAME_CONTRACT_TYPE','CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY', 'NAME_TYPE_SUITE', 'NAME_INCOME_TYPE', 'NAME_EDUCATION_TYPE', 'NAME_FAMILY_STATUS', 'NAME_HOUSING_TYPE', 'OCCUPATION_TYPE', 'WEEKDAY_APPR_PROCESS_START', 'ORGANIZATION_TYPE', 'HOUSETYPE_MODE', 'WALLSMATERIAL_MODE', 'EMERGENCYSTATE_MODE'] , prefix_sep = \"_\")\n",
    "OneHotEncoded_test_subset = pd.get_dummies(imputed_cat_testset, columns =  ['NAME_CONTRACT_TYPE','CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY', 'NAME_TYPE_SUITE', 'NAME_INCOME_TYPE', 'NAME_EDUCATION_TYPE', 'NAME_FAMILY_STATUS', 'NAME_HOUSING_TYPE', 'OCCUPATION_TYPE', 'WEEKDAY_APPR_PROCESS_START', 'ORGANIZATION_TYPE', 'HOUSETYPE_MODE', 'WALLSMATERIAL_MODE', 'EMERGENCYSTATE_MODE'] , prefix_sep = \"_\")\n",
    "    \n",
    "      \n",
    "print('OneHotEncoded Train shape = {}'.format(OneHotEncoded_train_subset.shape))\n",
    "print('OneHotEncoded Test shape = {}'.format(OneHotEncoded_test_subset.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OneHotEncoded_train_subset contains -\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME_CONTRACT_TYPE_Cash loans</th>\n",
       "      <th>NAME_CONTRACT_TYPE_Revolving loans</th>\n",
       "      <th>CODE_GENDER_F</th>\n",
       "      <th>CODE_GENDER_M</th>\n",
       "      <th>CODE_GENDER_XNA</th>\n",
       "      <th>FLAG_OWN_CAR_N</th>\n",
       "      <th>FLAG_OWN_CAR_Y</th>\n",
       "      <th>FLAG_OWN_REALTY_N</th>\n",
       "      <th>FLAG_OWN_REALTY_Y</th>\n",
       "      <th>NAME_TYPE_SUITE_Children</th>\n",
       "      <th>...</th>\n",
       "      <th>HOUSETYPE_MODE_terraced house</th>\n",
       "      <th>WALLSMATERIAL_MODE_Block</th>\n",
       "      <th>WALLSMATERIAL_MODE_Mixed</th>\n",
       "      <th>WALLSMATERIAL_MODE_Monolithic</th>\n",
       "      <th>WALLSMATERIAL_MODE_Others</th>\n",
       "      <th>WALLSMATERIAL_MODE_Panel</th>\n",
       "      <th>WALLSMATERIAL_MODE_Stone, brick</th>\n",
       "      <th>WALLSMATERIAL_MODE_Wooden</th>\n",
       "      <th>EMERGENCYSTATE_MODE_No</th>\n",
       "      <th>EMERGENCYSTATE_MODE_Yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 136 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   NAME_CONTRACT_TYPE_Cash loans  NAME_CONTRACT_TYPE_Revolving loans  \\\n",
       "0                              1                                   0   \n",
       "1                              1                                   0   \n",
       "2                              0                                   1   \n",
       "3                              1                                   0   \n",
       "4                              1                                   0   \n",
       "\n",
       "   CODE_GENDER_F  CODE_GENDER_M  CODE_GENDER_XNA  FLAG_OWN_CAR_N  \\\n",
       "0              0              1                0               1   \n",
       "1              1              0                0               1   \n",
       "2              0              1                0               0   \n",
       "3              1              0                0               1   \n",
       "4              0              1                0               1   \n",
       "\n",
       "   FLAG_OWN_CAR_Y  FLAG_OWN_REALTY_N  FLAG_OWN_REALTY_Y  \\\n",
       "0               0                  0                  1   \n",
       "1               0                  1                  0   \n",
       "2               1                  0                  1   \n",
       "3               0                  0                  1   \n",
       "4               0                  0                  1   \n",
       "\n",
       "   NAME_TYPE_SUITE_Children  ...  HOUSETYPE_MODE_terraced house  \\\n",
       "0                         0  ...                              0   \n",
       "1                         0  ...                              0   \n",
       "2                         0  ...                              0   \n",
       "3                         0  ...                              0   \n",
       "4                         0  ...                              0   \n",
       "\n",
       "   WALLSMATERIAL_MODE_Block  WALLSMATERIAL_MODE_Mixed  \\\n",
       "0                         0                         0   \n",
       "1                         1                         0   \n",
       "2                         0                         0   \n",
       "3                         0                         0   \n",
       "4                         0                         0   \n",
       "\n",
       "   WALLSMATERIAL_MODE_Monolithic  WALLSMATERIAL_MODE_Others  \\\n",
       "0                              0                          0   \n",
       "1                              0                          0   \n",
       "2                              0                          0   \n",
       "3                              0                          0   \n",
       "4                              0                          0   \n",
       "\n",
       "   WALLSMATERIAL_MODE_Panel  WALLSMATERIAL_MODE_Stone, brick  \\\n",
       "0                         0                                1   \n",
       "1                         0                                0   \n",
       "2                         1                                0   \n",
       "3                         1                                0   \n",
       "4                         1                                0   \n",
       "\n",
       "   WALLSMATERIAL_MODE_Wooden  EMERGENCYSTATE_MODE_No  EMERGENCYSTATE_MODE_Yes  \n",
       "0                          0                       1                        0  \n",
       "1                          0                       1                        0  \n",
       "2                          0                       1                        0  \n",
       "3                          0                       1                        0  \n",
       "4                          0                       1                        0  \n",
       "\n",
       "[5 rows x 136 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('OneHotEncoded_train_subset contains -')\n",
    "OneHotEncoded_train_subset.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set after OneHotEncoding : \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME_CONTRACT_TYPE_Cash loans</th>\n",
       "      <th>NAME_CONTRACT_TYPE_Revolving loans</th>\n",
       "      <th>CODE_GENDER_F</th>\n",
       "      <th>CODE_GENDER_M</th>\n",
       "      <th>FLAG_OWN_CAR_N</th>\n",
       "      <th>FLAG_OWN_CAR_Y</th>\n",
       "      <th>FLAG_OWN_REALTY_N</th>\n",
       "      <th>FLAG_OWN_REALTY_Y</th>\n",
       "      <th>NAME_TYPE_SUITE_Children</th>\n",
       "      <th>NAME_TYPE_SUITE_Family</th>\n",
       "      <th>...</th>\n",
       "      <th>HOUSETYPE_MODE_terraced house</th>\n",
       "      <th>WALLSMATERIAL_MODE_Block</th>\n",
       "      <th>WALLSMATERIAL_MODE_Mixed</th>\n",
       "      <th>WALLSMATERIAL_MODE_Monolithic</th>\n",
       "      <th>WALLSMATERIAL_MODE_Others</th>\n",
       "      <th>WALLSMATERIAL_MODE_Panel</th>\n",
       "      <th>WALLSMATERIAL_MODE_Stone, brick</th>\n",
       "      <th>WALLSMATERIAL_MODE_Wooden</th>\n",
       "      <th>EMERGENCYSTATE_MODE_No</th>\n",
       "      <th>EMERGENCYSTATE_MODE_Yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 133 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   NAME_CONTRACT_TYPE_Cash loans  NAME_CONTRACT_TYPE_Revolving loans  \\\n",
       "0                              1                                   0   \n",
       "1                              1                                   0   \n",
       "2                              1                                   0   \n",
       "3                              1                                   0   \n",
       "4                              1                                   0   \n",
       "\n",
       "   CODE_GENDER_F  CODE_GENDER_M  FLAG_OWN_CAR_N  FLAG_OWN_CAR_Y  \\\n",
       "0              1              0               1               0   \n",
       "1              0              1               1               0   \n",
       "2              0              1               0               1   \n",
       "3              1              0               1               0   \n",
       "4              0              1               0               1   \n",
       "\n",
       "   FLAG_OWN_REALTY_N  FLAG_OWN_REALTY_Y  NAME_TYPE_SUITE_Children  \\\n",
       "0                  0                  1                         0   \n",
       "1                  0                  1                         0   \n",
       "2                  0                  1                         0   \n",
       "3                  0                  1                         0   \n",
       "4                  1                  0                         0   \n",
       "\n",
       "   NAME_TYPE_SUITE_Family  ...  HOUSETYPE_MODE_terraced house  \\\n",
       "0                       0  ...                              0   \n",
       "1                       0  ...                              0   \n",
       "2                       0  ...                              0   \n",
       "3                       0  ...                              0   \n",
       "4                       0  ...                              0   \n",
       "\n",
       "   WALLSMATERIAL_MODE_Block  WALLSMATERIAL_MODE_Mixed  \\\n",
       "0                         0                         0   \n",
       "1                         0                         0   \n",
       "2                         0                         0   \n",
       "3                         0                         0   \n",
       "4                         0                         0   \n",
       "\n",
       "   WALLSMATERIAL_MODE_Monolithic  WALLSMATERIAL_MODE_Others  \\\n",
       "0                              0                          0   \n",
       "1                              0                          0   \n",
       "2                              0                          0   \n",
       "3                              0                          0   \n",
       "4                              0                          0   \n",
       "\n",
       "   WALLSMATERIAL_MODE_Panel  WALLSMATERIAL_MODE_Stone, brick  \\\n",
       "0                         0                                1   \n",
       "1                         1                                0   \n",
       "2                         1                                0   \n",
       "3                         1                                0   \n",
       "4                         1                                0   \n",
       "\n",
       "   WALLSMATERIAL_MODE_Wooden  EMERGENCYSTATE_MODE_No  EMERGENCYSTATE_MODE_Yes  \n",
       "0                          0                       1                        0  \n",
       "1                          0                       1                        0  \n",
       "2                          0                       1                        0  \n",
       "3                          0                       1                        0  \n",
       "4                          0                       1                        0  \n",
       "\n",
       "[5 rows x 133 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Test set after OneHotEncoding : ')\n",
    "OneHotEncoded_test_subset.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# SINCE WE USED GET_DUMMIES(), below LABEL ENCODER IS NO LONGER NEEDED.\n",
    "\n",
    "# Categorical features after performing label encoding(i.e. converting binary categorical vars to numeric)\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "LabelEncoder = preprocessing.LabelEncoder()\n",
    "LabelEncoder_count=0\n",
    "LabelEncoded_train = pd.DataFrame()\n",
    "LabelEncoded_test = pd.DataFrame()\n",
    "\n",
    "for col in imputed_cat_trainset:\n",
    "    if len(list(imputed_cat_trainset[col].unique())) <= 2:\n",
    "            \n",
    "            LabelEncoded_train[col] = LabelEncoder.fit_transform(imputed_cat_trainset[col])\n",
    "            LabelEncoded_test[col] = LabelEncoder.transform(imputed_cat_testset[col])\n",
    "            \n",
    "            # Keep track of how many columns were label encoded\n",
    "            LabelEncoder_count += 1\n",
    "\n",
    "print('LabelEncoding perfomred for {} columns in categorical portion of dataset'.format(LabelEncoder_count))\n",
    "print(LabelEncoded_train.head())\n",
    "print('\\n')\n",
    "print('Test set after label encoding : ')\n",
    "print(LabelEncoded_test.head())\n",
    "\n",
    "\n",
    "    Binarized_Train_CODE_GENDER =pd.DataFrame(LabelBinarizer.fit_transform(imputed_cat_trainset['CODE_GENDER']), columns='CODE_GENDER').astype(imputed_cat_trainset.dtypes.to_dict())\n",
    "    Binarized_Test_CODE_GENDER=pd.DataFrame(LabelBinarizer.transform(imputed_cat_testset['CODE_GENDER'])).astype(imputed_cat_trainset.dtypes.to_dict())\n",
    "\n",
    "Binarized_Train_CODE_GENDER.head()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  - Unlike LabelEncoder() which returns a dataframe, output of OneHotEncoder() is a numpy array. \n",
    "  \n",
    "  - Say when there are three classes one hot encoded returns 3 binarized columns. i.e. when one class is present (1) then automatically the other 2 class is 0. Hence the two columns will be highly correlated which is not desired. This is called as the “variable-trap”. In order to solve this, you can use the drop parameter in the OneHotEncoder.\n",
    "  \n",
    "  - The prefix_sep(“_”) is used to write column name [ “Column_Name”+ “_” + “Class_Name” ] and drop_first = True is used to avoid multicollinearity also called as \"variable trap\".\n",
    "  \n",
    "  - But we have not used drop_first = True, because, the order of classes is causing unwanted columns to remain and wanted cols to get remmoved. Example: in gender col for trainset, there were 3 classes - Female, Male & XNA. By using drop_first=True, code is dropping female and retaining XNA which we would anyways remove as XNA is not present in Testset. We want to retain female & male. We cant use drop_last = True because for other cols, the order is different. \n",
    "  \n",
    "  - Now that we converted all cat vars to numeric format, notice that the shape (or num of cols) in train & test sets differ. Implies there were classes in train set that were not present in test set. Mismatch in cols between train & test sets will break model performance on testset. Hence align function must be applied to test & train sets to retain only those cols available in both sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of OneHotEncoded_trainset after align: (307511, 133)\n",
      "Shape of OneHotEncoded_testset after align: (48744, 133)\n",
      "Shape of imputed_num_trainset after align: (307511, 89)\n",
      "Shape of imputed_num_testset after align: (48744, 89)\n"
     ]
    }
   ],
   "source": [
    "# apply align func to sync cols in train & test sets\n",
    "\n",
    "OneHotEncoded_train_subset, OneHotEncoded_test_subset = OneHotEncoded_train_subset.align(OneHotEncoded_test_subset, join=\"inner\", axis=1)\n",
    "\n",
    "print('Shape of OneHotEncoded_trainset after align: {}'.format(OneHotEncoded_train_subset.shape))\n",
    "print('Shape of OneHotEncoded_testset after align: {}'.format(OneHotEncoded_test_subset.shape))\n",
    "\n",
    "# printing shape of num set as well as we require to concat them in next step\n",
    "print('Shape of imputed_num_trainset after align: {}'.format(imputed_num_trainset.shape))\n",
    "print('Shape of imputed_num_testset after align: {}'.format(imputed_num_testset.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Above result shows that rows of both cat & num sets are in sync. Cols of train & test sets are in sync. We can now proceed with concatination of cat & num vars to form a cleansed dataset.\n",
    " \n",
    " - Note: We havent yet addressed variable trap (Multicollinearity issue caused by using get_dummies(). We shall address it separately when calculating correlation\n",
    " \n",
    " - Merge() combines datasets as inner join by default. \n",
    " - join() combines datasets as left join by default.\n",
    " - concat() combines datasets as outer join by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of cleansed_trainset after align: (307511, 222)\n",
      "Shape of cleansed_testset after align: (48744, 222)\n"
     ]
    }
   ],
   "source": [
    "# Combine cat & num sets\n",
    "\n",
    "cleansed_trainset = pd.concat([OneHotEncoded_train_subset, imputed_num_trainset], axis = 1)\n",
    "cleansed_testset = pd.concat([OneHotEncoded_test_subset, imputed_num_testset], axis =1)\n",
    "\n",
    "print('Shape of cleansed_trainset after align: {}'.format(cleansed_trainset.shape))\n",
    "print('Shape of cleansed_testset after align: {}'.format(cleansed_testset.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Notice that original / initial trainset had only 122 cols. Now after creating dummy vars, there are 222 cols. So we increased features by 100 count. This could impact mmodel performance. \n",
    " - Let us see if we can reduce this number significantly by assessing correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of cleansed_trainset after adding back TARGET col: (307511, 223)\n",
      "Shape of cleansed_testset: (48744, 222)\n"
     ]
    }
   ],
   "source": [
    "#Adding TARET col to trainset\n",
    "\n",
    "cleansed_trainset['TARGET'] =target_var\n",
    "\n",
    "print('Shape of cleansed_trainset after adding back TARGET col: {}'.format(cleansed_trainset.shape))\n",
    "print('Shape of cleansed_testset: {}'.format(cleansed_testset.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Positive Correlations:\n",
      "\n",
      "                                          Column_name  Correlation_value\n",
      "0                                              TARGET           1.000000\n",
      "1                                          DAYS_BIRTH           0.078239\n",
      "2                         REGION_RATING_CLIENT_W_CITY           0.060893\n",
      "3                                REGION_RATING_CLIENT           0.058899\n",
      "4                            NAME_INCOME_TYPE_Working           0.057481\n",
      "5                              DAYS_LAST_PHONE_CHANGE           0.055218\n",
      "6                                       CODE_GENDER_M           0.054713\n",
      "7                                     DAYS_ID_PUBLISH           0.051457\n",
      "8                              REG_CITY_NOT_WORK_CITY           0.050994\n",
      "9   NAME_EDUCATION_TYPE_Secondary / secondary special           0.049824\n",
      "10                                     FLAG_EMP_PHONE           0.045982\n",
      "11                             REG_CITY_NOT_LIVE_CITY           0.044395\n",
      "12                                    FLAG_DOCUMENT_3           0.044346\n",
      "13                                  DAYS_REGISTRATION           0.041975\n",
      "14                           DEF_30_CNT_SOCIAL_CIRCLE           0.032602\n",
      "15                            LIVE_CITY_NOT_WORK_CITY           0.032518\n",
      "16                           DEF_60_CNT_SOCIAL_CIRCLE           0.031540\n",
      "17                      NAME_CONTRACT_TYPE_Cash loans           0.030896\n",
      "18                            OCCUPATION_TYPE_Drivers           0.030303\n",
      "19                     NAME_HOUSING_TYPE_With parents           0.029966\n",
      "20                    ORGANIZATION_TYPE_Self-employed           0.029139\n",
      "\n",
      "Most Negative Correlations:\n",
      "\n",
      "                              Column_name  Correlation_value\n",
      "203                            FLAG_PHONE          -0.023806\n",
      "204               HOUR_APPR_PROCESS_START          -0.024166\n",
      "205            NAME_FAMILY_STATUS_Married          -0.025043\n",
      "206   NAME_HOUSING_TYPE_House / apartment          -0.028555\n",
      "207                       FLAG_DOCUMENT_6          -0.028602\n",
      "208                        FLOORSMAX_MODE          -0.028631\n",
      "209                        FLOORSMAX_MEDI          -0.028989\n",
      "210                         FLOORSMAX_AVG          -0.029145\n",
      "211                            AMT_CREDIT          -0.030369\n",
      "212    NAME_CONTRACT_TYPE_Revolving loans          -0.030896\n",
      "213            REGION_POPULATION_RELATIVE          -0.037227\n",
      "214                       AMT_GOODS_PRICE          -0.039628\n",
      "215                         DAYS_EMPLOYED          -0.044932\n",
      "216                 ORGANIZATION_TYPE_XNA          -0.045987\n",
      "217            NAME_INCOME_TYPE_Pensioner          -0.046209\n",
      "218                         CODE_GENDER_F          -0.054704\n",
      "219  NAME_EDUCATION_TYPE_Higher education          -0.056593\n",
      "220                          EXT_SOURCE_1          -0.099152\n",
      "221                          EXT_SOURCE_3          -0.157397\n",
      "222                          EXT_SOURCE_2          -0.160303\n"
     ]
    }
   ],
   "source": [
    "# calculating correlation between independent vars & TARGET var\n",
    "\n",
    "correlations = cleansed_trainset.corr()['TARGET'].sort_values() \n",
    "\n",
    "Correlations_DF =pd.DataFrame(correlations.sort_values(ascending = False)).reset_index()\n",
    "Correlations_DF.columns = ['Column_name', 'Correlation_value']\n",
    "\n",
    "print('Most Positive Correlations:\\n')\n",
    "print(Correlations_DF.head(n=21)) # one more than -ve corr becasue it includes TARGET var as 100% positivelt correlated.\n",
    "print('\\nMost Negative Correlations:\\n')\n",
    "print(Correlations_DF.tail(n=20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Featured_Trainset shape = (307511, 40)\n",
      "Featured_Testset shape = (48744, 39)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EXT_SOURCE_2</th>\n",
       "      <th>EXT_SOURCE_3</th>\n",
       "      <th>EXT_SOURCE_1</th>\n",
       "      <th>NAME_EDUCATION_TYPE_Higher education</th>\n",
       "      <th>CODE_GENDER_F</th>\n",
       "      <th>NAME_INCOME_TYPE_Pensioner</th>\n",
       "      <th>DAYS_EMPLOYED</th>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <th>REGION_POPULATION_RELATIVE</th>\n",
       "      <th>NAME_CONTRACT_TYPE_Revolving loans</th>\n",
       "      <th>...</th>\n",
       "      <th>FLAG_DOCUMENT_3</th>\n",
       "      <th>DAYS_REGISTRATION</th>\n",
       "      <th>DEF_30_CNT_SOCIAL_CIRCLE</th>\n",
       "      <th>LIVE_CITY_NOT_WORK_CITY</th>\n",
       "      <th>DEF_60_CNT_SOCIAL_CIRCLE</th>\n",
       "      <th>NAME_CONTRACT_TYPE_Cash loans</th>\n",
       "      <th>OCCUPATION_TYPE_Drivers</th>\n",
       "      <th>NAME_HOUSING_TYPE_With parents</th>\n",
       "      <th>ORGANIZATION_TYPE_Self-employed</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.262949</td>\n",
       "      <td>0.139376</td>\n",
       "      <td>0.083037</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-637</td>\n",
       "      <td>351000.0</td>\n",
       "      <td>0.018801</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-3648.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.622246</td>\n",
       "      <td>0.510853</td>\n",
       "      <td>0.311267</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1188</td>\n",
       "      <td>1129500.0</td>\n",
       "      <td>0.003541</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1186.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.555912</td>\n",
       "      <td>0.729567</td>\n",
       "      <td>0.502130</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-225</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>0.010032</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-4260.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.650442</td>\n",
       "      <td>0.510853</td>\n",
       "      <td>0.502130</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-3039</td>\n",
       "      <td>297000.0</td>\n",
       "      <td>0.008019</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-9833.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.322738</td>\n",
       "      <td>0.510853</td>\n",
       "      <td>0.502130</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3038</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>0.028663</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-4311.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   EXT_SOURCE_2  EXT_SOURCE_3  EXT_SOURCE_1  \\\n",
       "0      0.262949      0.139376      0.083037   \n",
       "1      0.622246      0.510853      0.311267   \n",
       "2      0.555912      0.729567      0.502130   \n",
       "3      0.650442      0.510853      0.502130   \n",
       "4      0.322738      0.510853      0.502130   \n",
       "\n",
       "   NAME_EDUCATION_TYPE_Higher education  CODE_GENDER_F  \\\n",
       "0                                     0              0   \n",
       "1                                     1              1   \n",
       "2                                     0              0   \n",
       "3                                     0              1   \n",
       "4                                     0              0   \n",
       "\n",
       "   NAME_INCOME_TYPE_Pensioner  DAYS_EMPLOYED  AMT_GOODS_PRICE  \\\n",
       "0                           0           -637         351000.0   \n",
       "1                           0          -1188        1129500.0   \n",
       "2                           0           -225         135000.0   \n",
       "3                           0          -3039         297000.0   \n",
       "4                           0          -3038         513000.0   \n",
       "\n",
       "   REGION_POPULATION_RELATIVE  NAME_CONTRACT_TYPE_Revolving loans  ...  \\\n",
       "0                    0.018801                                   0  ...   \n",
       "1                    0.003541                                   0  ...   \n",
       "2                    0.010032                                   1  ...   \n",
       "3                    0.008019                                   0  ...   \n",
       "4                    0.028663                                   0  ...   \n",
       "\n",
       "   FLAG_DOCUMENT_3  DAYS_REGISTRATION  DEF_30_CNT_SOCIAL_CIRCLE  \\\n",
       "0                1            -3648.0                       2.0   \n",
       "1                1            -1186.0                       0.0   \n",
       "2                0            -4260.0                       0.0   \n",
       "3                1            -9833.0                       0.0   \n",
       "4                0            -4311.0                       0.0   \n",
       "\n",
       "   LIVE_CITY_NOT_WORK_CITY  DEF_60_CNT_SOCIAL_CIRCLE  \\\n",
       "0                        0                       2.0   \n",
       "1                        0                       0.0   \n",
       "2                        0                       0.0   \n",
       "3                        0                       0.0   \n",
       "4                        1                       0.0   \n",
       "\n",
       "   NAME_CONTRACT_TYPE_Cash loans  OCCUPATION_TYPE_Drivers  \\\n",
       "0                              1                        0   \n",
       "1                              1                        0   \n",
       "2                              0                        0   \n",
       "3                              1                        0   \n",
       "4                              1                        0   \n",
       "\n",
       "   NAME_HOUSING_TYPE_With parents  ORGANIZATION_TYPE_Self-employed  TARGET  \n",
       "0                               0                                0       1  \n",
       "1                               0                                0       0  \n",
       "2                               0                                0       0  \n",
       "3                               0                                0       0  \n",
       "4                               0                                0       0  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract only those columns for which correlation was high.\n",
    "\n",
    "Featured_Trainset = cleansed_trainset.loc[ : , ['EXT_SOURCE_2', 'EXT_SOURCE_3', 'EXT_SOURCE_1', 'NAME_EDUCATION_TYPE_Higher education', 'CODE_GENDER_F', 'NAME_INCOME_TYPE_Pensioner', 'DAYS_EMPLOYED', 'AMT_GOODS_PRICE', 'REGION_POPULATION_RELATIVE', 'NAME_CONTRACT_TYPE_Revolving loans', 'AMT_CREDIT', 'FLOORSMAX_AVG', 'FLOORSMAX_MEDI', 'FLOORSMAX_MODE', 'FLAG_DOCUMENT_6', 'NAME_HOUSING_TYPE_House / apartment', 'NAME_FAMILY_STATUS_Married', 'HOUR_APPR_PROCESS_START', 'FLAG_PHONE', 'DAYS_BIRTH', 'REGION_RATING_CLIENT_W_CITY', 'REGION_RATING_CLIENT', 'NAME_INCOME_TYPE_Working', 'DAYS_LAST_PHONE_CHANGE', 'CODE_GENDER_M', 'DAYS_ID_PUBLISH', 'REG_CITY_NOT_WORK_CITY', 'NAME_EDUCATION_TYPE_Secondary / secondary special', 'FLAG_EMP_PHONE', 'REG_CITY_NOT_LIVE_CITY', 'FLAG_DOCUMENT_3', 'DAYS_REGISTRATION', 'DEF_30_CNT_SOCIAL_CIRCLE', 'LIVE_CITY_NOT_WORK_CITY', 'DEF_60_CNT_SOCIAL_CIRCLE', 'NAME_CONTRACT_TYPE_Cash loans', 'OCCUPATION_TYPE_Drivers', 'NAME_HOUSING_TYPE_With parents', 'ORGANIZATION_TYPE_Self-employed', 'TARGET']] \n",
    "Featured_Testset = cleansed_testset.loc[ : , ['EXT_SOURCE_2', 'EXT_SOURCE_3', 'EXT_SOURCE_1', 'NAME_EDUCATION_TYPE_Higher education', 'CODE_GENDER_F', 'NAME_INCOME_TYPE_Pensioner', 'DAYS_EMPLOYED', 'AMT_GOODS_PRICE', 'REGION_POPULATION_RELATIVE', 'NAME_CONTRACT_TYPE_Revolving loans', 'AMT_CREDIT', 'FLOORSMAX_AVG', 'FLOORSMAX_MEDI', 'FLOORSMAX_MODE', 'FLAG_DOCUMENT_6', 'NAME_HOUSING_TYPE_House / apartment', 'NAME_FAMILY_STATUS_Married', 'HOUR_APPR_PROCESS_START', 'FLAG_PHONE', 'DAYS_BIRTH', 'REGION_RATING_CLIENT_W_CITY', 'REGION_RATING_CLIENT', 'NAME_INCOME_TYPE_Working', 'DAYS_LAST_PHONE_CHANGE', 'CODE_GENDER_M', 'DAYS_ID_PUBLISH', 'REG_CITY_NOT_WORK_CITY', 'NAME_EDUCATION_TYPE_Secondary / secondary special', 'FLAG_EMP_PHONE', 'REG_CITY_NOT_LIVE_CITY', 'FLAG_DOCUMENT_3', 'DAYS_REGISTRATION', 'DEF_30_CNT_SOCIAL_CIRCLE', 'LIVE_CITY_NOT_WORK_CITY', 'DEF_60_CNT_SOCIAL_CIRCLE', 'NAME_CONTRACT_TYPE_Cash loans', 'OCCUPATION_TYPE_Drivers', 'NAME_HOUSING_TYPE_With parents', 'ORGANIZATION_TYPE_Self-employed']]\n",
    "\n",
    "print('Featured_Trainset shape = {}'.format(Featured_Trainset.shape))\n",
    "print('Featured_Testset shape = {}'.format(Featured_Testset.shape))\n",
    "Featured_Trainset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of TrainX = (307511, 39)\n",
      "shape of TrainY = (307511, 1)\n",
      "shape of TestX = (48744, 39)\n"
     ]
    }
   ],
   "source": [
    "# standarize extracted features\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "TrainY = pd.DataFrame(Featured_Trainset['TARGET']).reset_index()\n",
    "TrainY.columns = ['Index', 'TARGET']\n",
    "TrainY.drop(['Index'], axis = 1, inplace = True)\n",
    "TrainTemp = Featured_Trainset.drop(['TARGET'], axis = 1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "TrainX = pd.DataFrame(scaler.fit_transform(TrainTemp), columns = TrainTemp.columns).astype(TrainTemp.dtypes.to_dict())\n",
    "TestX = pd.DataFrame(scaler.transform(Featured_Testset), columns = Featured_Testset.columns).astype(Featured_Testset.dtypes.to_dict())\n",
    "\n",
    "\n",
    "print('shape of TrainX = {}'.format(TrainX.shape))\n",
    "print('shape of TrainY = {}'.format(TrainY.shape))\n",
    "print('shape of TestX = {}'.format(TestX.shape))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   - Now our Train set, target var & test sets are ready for machine learning modelling.  \n",
    "   - Before we begin modelling let us save these processed datasets so that for future executions we do not have to re-run all the pre-processing steps that we did till now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Export of pre-processed datasets is completed.\n"
     ]
    }
   ],
   "source": [
    "# Exporting preprocessed & final TrainX, TrainY & TestX datasets\n",
    "\n",
    "TrainX.to_csv(r'D:\\Study Material\\Datascience\\Project- Home Loan Credit Risk Modelling\\Dataset\\TrainX.csv')\n",
    "TrainY.to_csv(r'D:\\Study Material\\Datascience\\Project- Home Loan Credit Risk Modelling\\Dataset\\TrainY.csv')\n",
    "TestX.to_csv(r'D:\\Study Material\\Datascience\\Project- Home Loan Credit Risk Modelling\\Dataset\\TestX.csv')\n",
    "\n",
    "print('Export of pre-processed datasets is completed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Notice that index values have also got exported as column # 1 . Therefore, when importing above files for future use,ensure to remove / drop that column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processed TrainX shape : (307511, 39)\n",
      "Pre-processed TrainY shape : (307511, 1)\n",
      "Pre-processed TestX shape : (48744, 39)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# USE THIS CODE TO AVOID RUNNING ALL ABOVE CELLS OF CODE \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "TrainX = pd.read_csv(r'D:\\Study Material\\Datascience\\Project- Home Loan Credit Risk Modelling\\Dataset\\TrainX.csv')\n",
    "TrainY = pd.read_csv(r'D:\\Study Material\\Datascience\\Project- Home Loan Credit Risk Modelling\\Dataset\\TrainY.csv')\n",
    "TestX = pd.read_csv(r'D:\\Study Material\\Datascience\\Project- Home Loan Credit Risk Modelling\\Dataset\\TestX.csv')\n",
    "\n",
    "\n",
    "TrainX.drop(TrainX.columns[0], axis = 1, inplace = True)\n",
    "TrainY.drop(TrainY.columns[0], axis = 1, inplace = True)\n",
    "TestX.drop(TestX.columns[0], axis = 1, inplace = True)\n",
    "\n",
    "print (\"Pre-processed TrainX shape : {}\".format(TrainX.shape))\n",
    "print (\"Pre-processed TrainY shape : {}\".format(TrainY.shape))\n",
    "print (\"Pre-processed TestX shape : {}\".format(TestX.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify which Machine learning Model fits better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please wait while models train..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model = LR ; auroc: 0.739116152635978 ;  (Training Time: 1.1508249084154765mins)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:514: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:514: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:514: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:514: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:514: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model = KNN ; auroc: 0.5915554618987878 ;  (Training Time: 37.24104069471359mins)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:514: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:514: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:514: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:514: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:514: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model = RF ; auroc: 0.6444068546291812 ;  (Training Time: 1.0324944337209065mins)\n"
     ]
    }
   ],
   "source": [
    "# Perform cross validation with various ML models to check which one gives higher performance\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import time \n",
    "\n",
    "\n",
    "num_folds = 5\n",
    "seed = 1\n",
    "scoring = 'roc_auc'\n",
    "models = [('LR', LogisticRegression()), ('KNN', KNeighborsClassifier()), ('RF', RandomForestClassifier())]\n",
    "\n",
    "# iterate over models and print cross val scores\n",
    "results = []\n",
    "names = []\n",
    "print('Please wait while models train..')\n",
    "\n",
    "for name, model in models:\n",
    "    \n",
    "    # start timer\n",
    "    start = time.time()\n",
    "    \n",
    "    # Cross Validation\n",
    "    kfold = KFold(n_splits=num_folds, random_state=seed)  #is this default method or user defined?\n",
    "    cv_results = cross_val_score(model, TrainX, TrainY, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    \n",
    "    # stop timing\n",
    "    end = time.time()\n",
    "    time_run = (end - start)/60\n",
    "    \n",
    "    print(\"Model = {} ; auroc: {} ;  (Training Time: {}mins)\".format(name, cv_results.mean(), time_run))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - As per above generated results, we can infer that Random Forest was the fastest, but Logistic regression returned a better accuracy measure. \n",
    " - Let us fine tune RandomForests to see if it can yield a better performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ### Hypderparameter Tuning\n",
    "  \n",
    "  - Now that we have identified which model classifier is better, let us fine tune the selected model to improve performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters are - RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=4, max_features='log2', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n",
      "\n",
      "\n",
      "Performance score for the best estimators is - 0.9192711805431351\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# declare hyperparameters to tune the model\n",
    "hyperparameters = [{'n_estimators': [25, 50, 75], 'max_features': ['auto']},\n",
    "                   {'n_estimators': [10, 60, 100], 'max_features': ['log2', 'sqrt'], 'max_depth' : [4, 6]}\n",
    "                  ]\n",
    "\n",
    "# use grid search with cross validation to run on various parameters of the model.\n",
    "# fix the warnings in TrainY by using ravel() to change shape of Y from (48744,1) which is a dataframe to (48744,) which is a 1D numpy array\n",
    "model = GridSearchCV(RandomForestClassifier(), hyperparameters, cv = 3)\n",
    "model.fit(TrainX, TrainY.values.ravel())\n",
    "\n",
    "\n",
    "print('Best hyperparameters are - {}'.format(model.best_estimator_))\n",
    "print('\\n')\n",
    "print('Performance score for the best estimators is - {}'.format(model.best_score_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Clearly, accuracy of  Random forest model has boosted from 64% to 91.9%, which is higher than that generated by Logistic regression (73.9%)\n",
    " - Hence we shall finalize on this model with the hyperparameters that generated greater performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Dataset on FINALIZED model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=4, max_features='log2', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the trainset with finalized & hypermetrized model.\n",
    "\n",
    "Final_model = RandomForestClassifier(n_estimators=10, max_features='log2', max_depth=4, criterion='gini')\n",
    "Final_model.fit(TrainX, TrainY.values.ravel())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Since we do not have actual results for TestY, we wont be able to specifically calculate accuracy_score(TestY, Predicted_Y) or f1_score(TestY, Predicted_Y)\n",
    "  - So let's proceed with predicting the probablity of customer to default from loan repayment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Predictions of which customer will default from repaying home loan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48744,)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Predicted_Y = Final_model.predict_proba(TestX)[:, 1]\n",
    "Predicted_Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of Final Resullts_Set with predicted probabilities of defaultering home loan = (48744, 2)\n",
      "Highest probability of defaulters are : \n",
      "       SK_ID_CURR    TARGET\n",
      "31866      331976  0.255603\n",
      "11936      186695  0.244039\n",
      "16684      220600  0.242674\n",
      "5494       140101  0.236204\n",
      "10527      176483  0.235770\n",
      "\n",
      "\n",
      "Least probable defaulters are : \n",
      "       SK_ID_CURR    TARGET\n",
      "15435      211342  0.036149\n",
      "22027      259932  0.035292\n",
      "34405      351243  0.035292\n",
      "45969      435999  0.035292\n",
      "26140      290270  0.035292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "# Store & Export Predicted probabilities to a resultset file.\n",
    "\n",
    "initial_testset = pd.read_csv(r'D:\\Study Material\\Datascience\\Project- Home Loan Credit Risk Modelling\\Dataset\\application_test.csv')\n",
    "\n",
    "Results_Set = initial_testset[['SK_ID_CURR']]\n",
    "Results_Set['TARGET'] = Predicted_Y\n",
    "\n",
    "\n",
    "Results_Set.sort_values(by=['TARGET'], ascending = False, inplace=True)\n",
    "\n",
    "print('shape of Final Resullts_Set with predicted probabilities of defaultering home loan = {}'.format(Results_Set.shape))\n",
    "print('Highest probability of defaulters are : ')\n",
    "print(Results_Set.head())\n",
    "print('\\n')\n",
    "print('Least probable defaulters are : ')\n",
    "print(Results_Set.tail())\n",
    "\n",
    "Results_Set.to_csv(r'D:\\Study Material\\Datascience\\Project- Home Loan Credit Risk Modelling\\Dataset\\Result_PredictedProb_RandomForest.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## That's all folks! \n",
    "\n",
    "#### Happy Machine Learning :) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
